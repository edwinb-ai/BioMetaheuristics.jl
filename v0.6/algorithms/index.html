<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Implementations · Newtman.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>Newtman.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Home</a></li><li><a class="toctext" href="../guide/">Guide</a></li><li class="current"><a class="toctext" href>Implementations</a><ul class="internal"><li><a class="toctext" href="#Particle-Swarm-Optimization-1">Particle Swarm Optimization</a></li><li><a class="toctext" href="#Simulated-Annealing-1">Simulated Annealing</a></li><li><a class="toctext" href="#References-1">References</a></li></ul></li><li><a class="toctext" href="../benchmarks/">Benchmark functions</a></li><li><a class="toctext" href="../reference/">Reference</a></li><li><a class="toctext" href="../license/">License</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Implementations</a></li></ul><a class="edit-page" href="https://github.com/edwinb-ai/Newtman.jl/blob/master/docs/src/algorithms.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Implementations</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="implementations-docs-1" href="#implementations-docs-1">Algorithms</a></h1><p>The following <strong>algorithms</strong> are implemented:</p><h2><a class="nav-anchor" id="Particle-Swarm-Optimization-1" href="#Particle-Swarm-Optimization-1">Particle Swarm Optimization</a></h2><p>This implementation is the modified Particle Swarm Optimization <a href="#footnote-1">[1]</a> where it employs an inertia weight <span>$\omega$</span> that controls convergence. This implementation uses <em>linear decay</em> for the inertia weight, which lowers the value of  <span>$\omega$</span> iteratively until it reaches the default minimum of <span>$\omega = 0.4$</span>.</p><p>The <strong>update rules</strong> for the particles are the following:</p><div>\[x_{i+1} = x_i + v_{i+1} \\
v_{i+1} = \omega v_i + \varphi_1 \beta_1 (p_i - x_i) + \varphi_2 \beta_2 (p_g - x_i) \\
\omega = \omega - \eta\]</div><p>where <span>$\beta_1$</span> and <span>$\beta_2$</span> are uniformly distributed random numbers; <span>$\varphi_1$</span> and <span>$\varphi_2$</span> are the momentum coefficients; <span>$p_i$</span> is the previous individual best position and <span>$p_g$</span> is the privious global best position of the population; finally <span>$\eta$</span> is the weight decay, currently implemented as</p><div>\[\eta = \frac{(0.9 - 0.4)}{n}\]</div><p>where <span>$0.9$</span> is the original default value for <span>$\omega$</span>, <span>$0.4$</span> is the default minimum as explained before and <span>$n$</span> is the total number of iterations the algorithm is run. This guarantees that the weight decays linearly.</p><h2><a class="nav-anchor" id="Simulated-Annealing-1" href="#Simulated-Annealing-1">Simulated Annealing</a></h2><h3><a class="nav-anchor" id="Classic-version-1" href="#Classic-version-1">Classic version</a></h3><p>This implementation <a href="#footnote-2">[2]</a> uses the following logarithmic cooling schedule</p><div>\[T_{new}(t) = T_0 \frac{\log{(2)}}{\log{1 + t}}\]</div><p>to obtain a new temperature each iteration, starting from an initial temperature <span>$T_0$</span>.</p><p>This implementation searches possible candidate solutions by sampling from an approximate Boltzmann distribution, drawn as a normal distribution like so</p><div>\[g_{sol}(x) = \mathcal{N}(0, 1) * \sigma \\
x_{sol} = x_{prev} + g_{sol}(x)\]</div><p>where <span>$g_{sol}(x)$</span> is an array filled with random values sampled from an approximate normal standard distribution with standard deviation <span>$\sigma = \sqrt{T_{new}(t)}$</span> which corresponds to the previously found temperature. With this array, the new solution is computed as the previous (best) solution, <span>$x_{sol}$</span>, and adding the sampled array.</p><p>Finally, the Metropolis-Hastings algorithm is defined as</p><div>\[P(x_{sol} \leftarrow x_{old}) = 1.0 \qquad f(x_{sol}) &lt; f(x_{old}) \\
P(x_{sol} \leftarrow x_{old}) = e^{(\Delta / T_{new}(t))} \qquad f(x_{sol}) \geq f(x_{old})\]</div><p>where <span>$\Delta = f(x_{old}) - f(x_{sol})$</span>.</p><h3><a class="nav-anchor" id="Generalized-version-1" href="#Generalized-version-1">Generalized version</a></h3><p>This is the implementation developed by Tsallis &amp; Stariolo <a href="#footnote-2">[2]</a> following Tsallis&#39; theory on the generalization of the extensive entropy developed in Statistical Mechanics. This implementation has as special cases the classic version described above and the <em>fast</em> version developed by Szu &amp; Hartley <a href="#footnote-3">[3]</a>.</p><p>This implementation is quite interesting as it uses the Tsallis entropy defined <a href="#footnote-4">[4]</a> as</p><div>\[S_q = k_B \frac{1-\sum_q p_i^q}{q_1}\]</div><p>where <span>$q$</span> is the so-called <strong>Tsallis parameter</strong>. By developing fundamental Statistical Mechanics theory and combining it with Gibbs&#39; ensemble theory (I&#39;m skipping all the development, it&#39;s quite extensive, pun intended), we arrive at a Metropolis-Hastings-like acceptance probability</p><div>\[P_{q_a}(x_{sol} \leftarrow x_{old}) = 1 \qquad f(x_{sol}) &lt; f(x_{old}) \\

P_{q_a}(x_{sol} \leftarrow x_{old}) = \frac{1}{[1+(q_a-1)\Delta / T_{new}(t)]^{(1/(q_a-1))}} \qquad f(x_{sol}) \geq f(x_{old})\]</div><p>there is a lot to unpack here, so we will go step by step.</p><p>Firstly, the <strong>cooling schedule</strong> is now defined as</p><div>\[T_{q_v}^V (t) = \frac{2^{q_v-1}-1}{(1+t)^{q_v-1}-1}\]</div><div>\[T_{new}(t) = T_0\ T_{q_v}^V (t)\]</div><p>where <span>$T_0$</span> is the initial temperature.</p><p>Then we have the neighbor sampling distribution defined as</p><div>\[g_{q_v}(\Delta x) = \left(\frac{q_{v}-1}{\pi}\right)^{D/2}

\frac{\Gamma\left(\frac{1}{q_{v}-1}+\frac{D-1}{2}\right)}{\Gamma\left(\frac{1}{q_{v}-1}-\frac{1}{2}\right)}

\frac{[T_{q_v}^V (t)]^{-\frac{D}{3-q_v}}}{\left(1+(q_v-1)\frac{(\Delta x)^2}{[T_{q_v}^V (t)]^{\frac{2}{3-q_v}}}\right)^{\frac{1}{q_V+1}+\frac{D-1}{2}}} \\

\forall D, \forall q_V\]</div><p>where <span>$\Delta x = x_{sol} - x_{old}$</span>, and <span>$\Gamma$</span> denotes the <a href="https://mathworld.wolfram.com/GammaFunction.html">Gamma function</a>. As you can see, this distribution is very complicated, but in the original paper <a href="#footnote-2">[2]</a> Tsallis &amp; Stariolo provide an algorithm where they approximate this distribution as a <a href="https://en.wikipedia.org/wiki/L%C3%A9vy_distribution">Lévy distribution</a>. This algorithm is provided in the paper and it&#39;s the one used in this implementation.</p><p>With this, we update the neighbor solution as before <span>$x_{sol} = x_{old} + g_{q_v}(\Delta x)$</span> and then we employ the Metropolis-Hastings algorithm.</p><p>Lastly, an important case is when <span>$q_A &lt; 0$</span> because the update rule is now undetermined, so we employ the following update rule</p><div>\[P_{q_a}(x_{sol} \leftarrow x_{old}) = 1 \qquad f(x_{sol}) &lt; f(x_{old}) \\

P_{q_a}(x_{sol} \leftarrow x_{old}) = [1+(q_a-1)\Delta / T_{new}(t)]^{-1} \qquad f(x_{sol}) \geq f(x_{old})\]</div><p>which means that we always reject the solution <span>$x_{sol}$</span> whenever the proposition <span>$[1+(q_a-1)\Delta / T_{new}(t)] &lt; 0$</span> is true.</p><h2><a class="nav-anchor" id="References-1" href="#References-1">References</a></h2><div class="footnote" id="footnote-1"><a href="#footnote-1"><strong>[1]</strong></a><p>Eberhart, R. C., &amp; Shi, Y. (2000, July). Comparing inertia weights and constriction factors in particle swarm optimization. In Proceedings of the 2000 congress on evolutionary computation. CEC00 (Cat. No. 00TH8512) (Vol. 1, pp. 84-88). IEEE.</p></div><div class="footnote" id="footnote-2"><a href="#footnote-2"><strong>[2]</strong></a><p>C. Tsallis and D. A. Stariolo, “Generalized Simulated Annealing,” Physica A: Statistical Mechanics and its Applications, vol. 233, no. 1–2, pp. 395–406, Nov. 1996, doi: 10.1016/S0378-4371(96)00271-3.</p></div><div class="footnote" id="footnote-3"><a href="#footnote-3"><strong>[3]</strong></a><p>Szu, H., &amp; Hartley, R. (1987). Fast simulated annealing. Physics letters A, 122(3-4), 157-162.</p></div><div class="footnote" id="footnote-4"><a href="#footnote-4"><strong>[4]</strong></a><p>C. Tsallis, “Possible generalization of Boltzmann-Gibbs statistics,” J Stat Phys, vol. 52, no. 1, pp. 479–487, Jul. 1988, doi: 10.1007/BF01016429.</p></div><footer><hr/><a class="previous" href="../guide/"><span class="direction">Previous</span><span class="title">Guide</span></a><a class="next" href="../benchmarks/"><span class="direction">Next</span><span class="title">Benchmark functions</span></a></footer></article></body></html>
