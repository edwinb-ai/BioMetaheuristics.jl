<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Parallel evaluation and simple statistics Â· Newtman.jl</title><link rel="canonical" href="https://edwinb-ai.github.io/Newtman.jl/stable/api/"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">Newtman.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../theory/">Theory</a></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../examples/">Implementations and proof of concept</a></li><li class="is-active"><a class="tocitem" href>Parallel evaluation and simple statistics</a><ul class="internal"><li><a class="tocitem" href="#Setting-up"><span>Setting up</span></a></li><li><a class="tocitem" href="#Code-set-up"><span>Code set up</span></a></li><li><a class="tocitem" href="#Parallel-evaluation"><span>Parallel evaluation</span></a></li><li><a class="tocitem" href="#Conclusions"><span>Conclusions</span></a></li></ul></li></ul></li><li><a class="tocitem" href="../algorithms/">Implementations</a></li><li><a class="tocitem" href="../benchmarks/">Benchmark functions</a></li><li><a class="tocitem" href="../reference/">Reference</a></li><li><a class="tocitem" href="../license/">License</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Examples</a></li><li class="is-active"><a href>Parallel evaluation and simple statistics</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Parallel evaluation and simple statistics</a></li></ul></nav><div class="docs-right"><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Parallel-evaluation-and-simple-statistics"><a class="docs-heading-anchor" href="#Parallel-evaluation-and-simple-statistics">Parallel evaluation and simple statistics</a><a id="Parallel-evaluation-and-simple-statistics-1"></a><a class="docs-heading-anchor-permalink" href="#Parallel-evaluation-and-simple-statistics" title="Permalink"></a></h1><p>In this example we will be looking at a way to evaluate several times a given problem by exploiting a distributed computing strategy known as <strong>embarrasingly parallel</strong> execution.</p><p>The idea is very simple: compute the same problem several times, in parallel, and collect the results at the end. This should work well with metaheuristics due to the following properties:</p><ul><li>Metaheuristics are <em>self-contained,</em> meaning that they possess their own RNG and their own search space.</li><li>Due to the fact that solutions are searched with a random component, independent runs should be able to give independent results.</li></ul><p>With this in mind, we can use the fantastic parallel capabilities of <code>Julia</code> and show how easy it is to obtain some simple, but meaningful statistics for a given optimization problem.</p><p>With this we want to also show that this is the <strong>right way</strong> to use this package. We should <em>always</em> run several independent solvers to obtain good statistics. We must <strong>never</strong> settle with just one run from the solver.</p><h2 id="Setting-up"><a class="docs-heading-anchor" href="#Setting-up">Setting up</a><a id="Setting-up-1"></a><a class="docs-heading-anchor-permalink" href="#Setting-up" title="Permalink"></a></h2><p>In order to use the multithreading capabilities of <code>Julia</code>, we need to launch the REPL using all the threads we can afford.</p><p>For instance, the computer where this example is currently being executed has 8 physical cores, so I should launch my <code>Julia</code> REPL like so</p><pre><code class="language-shell">JULIA_NUM_THREADS=8 julia</code></pre><p>This will launch the REPL with 8 cores ready to be used. We can check this by entering the following in the REPL,</p><pre><code class="language-julia">julia&gt; using Base.Threads
julia&gt; nthreads()</code></pre><p>making sure that this matches the same number introduced with the variable <code>JULIA_NUM_THREADS</code>.</p><p>You should replace the number of threads, in this case 8, with the number of threads that you wish.</p><h2 id="Code-set-up"><a class="docs-heading-anchor" href="#Code-set-up">Code set up</a><a id="Code-set-up-1"></a><a class="docs-heading-anchor-permalink" href="#Code-set-up" title="Permalink"></a></h2><p>First, let us import all the necessary modules we will need for this example.</p><pre><code class="language-julia">using Newtman
using Newtman.TestFunctions
using Base.Threads
using Statistics
using BenchmarkTools</code></pre><p>Now, let us create some setup functions. First, we will be using the <code>optimize</code> interface to solve the <a href="../reference/#Newtman.TestFunctions.Levy"><code>Levy</code></a> optimization problem. This function just wraps the <code>optimize</code> function and returns the solution vector from the problem.</p><p>We will be using Particle Swarm Optimization (PSO), with 20,000 iterations. It is very important to note that no specific RNG is being used. This tells the <code>optimize</code> function to always use a new, truly randomly seeded RNG.</p><pre><code class="language-julia">function solve_problem(dim)
    val = optimize(Levy(), zeros(dim), [-35.0, 35.0], PSO(); iters=20_000)

    return val.x
end;</code></pre><h3 id="Some-benchmarks"><a class="docs-heading-anchor" href="#Some-benchmarks">Some benchmarks</a><a id="Some-benchmarks-1"></a><a class="docs-heading-anchor-permalink" href="#Some-benchmarks" title="Permalink"></a></h3><p>Before we continue, I would like to show a benchmark of the PSO implementation. We will use the fantastic <a href="https://github.com/JuliaCI/BenchmarkTools.jl"><code>BenchmarkTools.jl</code></a> to check the time it takes to finish a single optimization problem.</p><p>Here, we will solve a 50-dimensional Levy optimization problem. We are not really interested if the solution is accurate, just the timing. We will deal with accuracy in the next subsection.</p><pre><code class="language-julia">b = @benchmark solve_problem(50);
b</code></pre><pre><code class="language-none">BenchmarkTools.Trial: 
  memory estimate:  37.09 GiB
  allocs estimate:  184553015
  --------------
  minimum time:     20.916 s (48.39% GC)
  median time:      20.916 s (48.39% GC)
  mean time:        20.916 s (48.39% GC)
  maximum time:     20.916 s (48.39% GC)
  --------------
  samples:          1
  evals/sample:     1</code></pre><p>Not bad at all. If it takes between 3-4 seconds to finish I think this is fairly good. Furthermore, it means that we can take advantage of how little it takes to run in order to really push the number of solvers to execute.</p><h2 id="Parallel-evaluation"><a class="docs-heading-anchor" href="#Parallel-evaluation">Parallel evaluation</a><a id="Parallel-evaluation-1"></a><a class="docs-heading-anchor-permalink" href="#Parallel-evaluation" title="Permalink"></a></h2><p>We now turn to the main event. We will launch several solvers using the previously created wrapper function in parallel. First off, we need another function to do so.</p><p>This function will use the <code>@threads</code> macro that enables a for-loop to run in parallel. The function has a matrix called <code>solutions</code> where we will be storing the solution vectors from each independent run.</p><p>We will call the solver in parallel and each time we will save the solutions vector. We will then compute the mean, median and standard deviation from all the independent runs and report that as the <em>true</em> value, and compare it to the <em>ground truth.</em></p><pre><code class="language-julia">function parallel_compute(;dim=50, total_iterations=50)
    solutions = Matrix{Float64}(undef, dim, total_iterations)

    @threads for i in 1:total_iterations
        solutions[:, i] = solve_problem(dim)
    end

    mean_result = mean(solutions; dims=2)
    median_result = median(solutions; dims=2)
    std_result = std(solutions; dims=2)

    return (mean_result, median_result, std_result)
end;</code></pre><p>We are ready to go. We will do 200 iterations in order to have good statistics.</p><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>Depending on your hardware this might take a long time. If that is the case stop the process and reduce the number of iterations.</p></div></div><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>Every time you do this exercise, new results will appear. This is normal for metaheuristics, and it is desired. We don&#39;t want reproducibility here, we aim for <em>statistical significance.</em></p></div></div><pre><code class="language-julia">Î¼, med, Ï = parallel_compute(;total_iterations=200);</code></pre><p>We can now check the results</p><p>Here is the mean value</p><pre><code class="language-julia">Î¼&#39;</code></pre><pre><code class="language-none">1Ã50 LinearAlgebra.Adjoint{Float64,Array{Float64,2}}:
 1.0  1.0  1.0  0.989071  1.0  1.0  1.0  1.0  1.0  0.994534  1.0  1.0  1.0  1.0  0.999999  1.0  1.0  1.0  0.994535  0.994535  1.0  0.994536  1.0  0.999999  1.0  1.0  0.989069  1.0  1.0  0.994535  0.999998  0.98907  0.98907  0.98907  0.994535  1.0  0.994535  1.0  0.994534  1.0  0.994535  1.0  0.999999  0.994535  0.994535  0.999999  1.0  0.994535  1.0  1.0</code></pre><p>Here is the median obtained</p><pre><code class="language-julia">med&#39;</code></pre><pre><code class="language-none">1Ã50 LinearAlgebra.Adjoint{Float64,Array{Float64,2}}:
 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0</code></pre><p>And finally, the standard deviation of the solution</p><pre><code class="language-julia">Ï&#39;</code></pre><pre><code class="language-none">1Ã50 LinearAlgebra.Adjoint{Float64,Array{Float64,2}}:
 5.85214e-6  8.49717e-6  5.11064e-6  0.109025  8.98645e-6  4.90472e-6  2.93619e-6  1.57354e-5  2.36602e-5  0.0772862  5.76815e-6  7.94483e-6  4.00857e-6  5.4588e-6  7.67163e-6  6.13454e-6  4.39584e-6  5.04256e-6  0.0772863  0.0772865  7.66157e-6  0.0772864  8.72139e-6  1.02898e-5  5.53272e-6  2.56498e-6  0.109024  1.02486e-5  6.3433e-6  0.0772864  1.40778e-5  0.109024  0.109025  0.109024  0.0772864  4.72514e-6  0.0772863  9.02386e-6  0.0772863  6.05015e-6  0.0772863  6.94921e-6  6.67594e-6  0.0772866  0.0772867  7.74873e-6  4.70179e-6  0.0772864  5.12988e-6  5.48866e-6</code></pre><p>Let us print the evaluation of the function on these results. First, the mean value.</p><pre><code class="language-julia">println(evaluate(Levy(), Î¼))</code></pre><pre><code class="language-none">0.00047890369305421924
</code></pre><p>Then, the median obtained.</p><pre><code class="language-julia">println(evaluate(Levy(), med))</code></pre><pre><code class="language-none">2.250210231361768e-14
</code></pre><h2 id="Conclusions"><a class="docs-heading-anchor" href="#Conclusions">Conclusions</a><a id="Conclusions-1"></a><a class="docs-heading-anchor-permalink" href="#Conclusions" title="Permalink"></a></h2><p>Recall that for the Levy function the solution is</p><div>\[\mathbf{x^*} = (1, \dots, 1)\]</div><p>and it should evaluate to</p><div>\[f(\mathbf{x^*}) = 0\]</div><p>It it safe to say that we have obtained those results, but we are <em>statistically sure</em> that these results are the <em>true</em> results, because we have several independent runs for the answer.</p><h3 id="On-the-use-of-the-median"><a class="docs-heading-anchor" href="#On-the-use-of-the-median">On the use of the median</a><a id="On-the-use-of-the-median-1"></a><a class="docs-heading-anchor-permalink" href="#On-the-use-of-the-median" title="Permalink"></a></h3><p>Notice that most of the time, the median result actually performs better than the mean result. This is somewhat expected, as the median is not really affected by poorly performant runs. Sometimes, independent runs will not give good results and when taken into account, the mean value will suffer greatly from this. The median, however, as a measure of the &quot;value in the middle&quot;, will not be so affected and a better estimation is expected.</p><p>We should always report both results, and conclude that whenever the final function evaluation is approximately the same with both the mean and the median, the solution is statistically acceptable for that particular problem.</p><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../examples/">Â« Implementations and proof of concept</a><a class="docs-footer-nextpage" href="../algorithms/">Implementations Â»</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Saturday 16 January 2021 00:19">Saturday 16 January 2021</span>. Using Julia version 1.5.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
