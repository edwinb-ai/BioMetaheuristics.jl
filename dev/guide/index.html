<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Guide · Newtman.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>Newtman.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="../search/"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../">Home</a></li><li class="current"><a class="toctext" href>Guide</a><ul class="internal"><li class="toplevel"><a class="toctext" href="#Examples-1">Examples</a></li><li><a class="toctext" href="#Embarrassingly-parallel-runs-1">Embarrassingly parallel runs</a></li><li class="toplevel"><a class="toctext" href="#A-primer-on-numerical-optimization-1">A primer on numerical optimization</a></li><li class="toplevel"><a class="toctext" href="#On-Convergence-1">On Convergence</a></li><li class="toplevel"><a class="toctext" href="#The-basics-of-nature-and-bio-inspired-metaheuristics-1">The basics of nature and bio-inspired metaheuristics</a></li><li><a class="toctext" href="#References-1">References</a></li></ul></li><li><a class="toctext" href="../reference/">Reference</a></li><li><a class="toctext" href="../license/">License</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href>Guide</a></li></ul><a class="edit-page" href="https://github.com/edwinb-ai/Newtman.jl/blob/master/docs/src/guide.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Guide</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Reach-1" href="#Reach-1">Reach</a></h1><p>This package should/could be used by:</p><ul><li><strong>Practitioners</strong>: people in need of a <em>black box optimization</em> framework for when they know very little about the problem at hand.</li><li><strong>Students</strong>: wanting to learn about nature-inspired algorithms, stochastic optimization or want a general survey of the current literature.</li><li><strong>Researchers</strong>: who want to employ different algorithms at once, test them or use them as comparison for their own developed algorithms.</li></ul><h1><a class="nav-anchor" id="Examples-1" href="#Examples-1">Examples</a></h1><p>Using <code>Newtman.jl</code> is fairly straightforward, first you define your own function to minimize, in this case we will use a popular function, the <a href="http://mathworld.wolfram.com/GriewankFunction.html">Griewank function</a> defined as</p><div>\[f(\mathbf{x}) = \sum_{i=1}^d \frac{x_i^2}{4000} - \prod_{i=1}^d \cos{\left( \frac{x_i}{\sqrt{i}}\right)} + 1\]</div><p>where <code>d</code> is the dimension of the problem. It&#39;s mostly evaluated within the boundaries <code>-100 \leq x_i \leq 100</code>, and it has a <strong>minimum</strong> at <code>\mathbf{x^*} = (0, \cdots, 0)</code>, and it evaluates to <code>f(\mathbf{x^*}) = 0</code>.</p><p>We define the function in <code>Julia</code> like this</p><pre><code class="language-julia">function griewank(x)
    first_term = sum(x .^ 2) / 4000
    # This variable will hold the result of the product,
    # the second term in the function definition from above
    second_term = 1.0
    for (idx, val) in enumerate(x)
        second_term *= cos(val / sqrt(idx))
    end

    return first_term - second_term + 1.0
end</code></pre><p>Now, we wish to find the minimum of this function, and fortunately we know the true value so we can compare it later, we can use some of the implementations from <code>Newtman.jl</code>, for example, <a href="../reference/#Newtman.PSO"><code>PSO</code></a>:</p><pre><code class="language-julia">using Newtman

val = PSO(griewank, Population(30, 20, -100.0, 100.0), 20000)</code></pre><p>In this script we have chosen 30 particles within the population, <code>d</code> is equal to 20, next we define the boundaries and finally we declare that the algorithm will run for 20000 maximum iterations until it stops, having <em>converged</em>.</p><p>When run, the above script will output something similar, but <strong>not equal</strong> to the following</p><pre><code class="language-julia">Results from Optimization
        Algorithm: PSO
        Design: [-3.0934433331801374e-9, -9.001706531841356e-9, 6.040569693490043e-9,
        3.651856870710123e-9, 1.7717846067288837e-8, -9.72251672565314e-9,
        -8.67994652424922e-10, -1.3340012700350453e-8, -6.538523861855145e-9,
        1.1096356317905482e-8, -3.0867381867588525e-8, 2.2709162725331985e-8,
        -2.359195570178852e-8, 1.2443005116661222e-8, 7.034134730754994e-10,
        2.6289422248296343e-8, -1.6855112446841584e-8, 2.5996179394073387e-8,
        -3.470098659476618e-8, 1.380018538766239e-8]
        Minimum: 0.0000
        Maximum iterations: 20000</code></pre><p>Within a certain tolerance of about <code>\epsilon</code> = 1e-8 we have found the <em>true</em> minimum of the function. We can actually check the value with the evaluation, notice that it actually returns <code>0</code>, as expected.</p><h2><a class="nav-anchor" id="Embarrassingly-parallel-runs-1" href="#Embarrassingly-parallel-runs-1">Embarrassingly parallel runs</a></h2><p><code>Newtman.jl</code> also provides an API to execute simultaneous, independent runs for the algorithms presented, for exaple, take the same function as before, the <code>Griewank</code> function, but let&#39;s now evaluate 10 runs of <code>PSO</code>, we call the function as before but we add a new parameter, the number of runs we would like to execute, and this looks like the following</p><pre><code class="language-julia">using Newtman

# Here the number 10 represents the number of independent runs
val = PSO(griewank, Population(30, 20, -100.0, 100.0), 20000, 10)</code></pre><p>Now this code will execute 10 different <code>PSO</code> instances in your computer using <code>Julia</code>&#39;s built-in multi-threading tools. In order for this to work as intended you must specify the number of threads you can use in your system by running a new <code>Julia</code> session with the following exported <em>environment variable.</em></p><pre><code class="language-shell">JULIA_NUM_THREADS=4 julia</code></pre><p>This will tell <code>Julia</code> to start with 4 threads enabled in your system, you can actually verify this by running the following in the REPL</p><pre><code class="language-julia">julia&gt; using Base.Threads
julia&gt; Threads.nthreads()

# output
4</code></pre><p>After waiting for a few seconds, the results <strong>might be</strong> similar to this</p><pre><code class="language-julia">Results from Optimization
        Algorithm: PSO
        Design: [-1.0817024888063792e-10, -2.6749621634017217e-9, 1.1040223452331079e-11,
        9.735685165578326e-9, 1.0439021918597697e-9, -6.85965962370804e-9,
        3.0345711112735914e-9, 2.551747398298418e-9, -9.549261142961494e-10,
        -2.589502577867808e-9, 3.175953614831133e-10, -9.060555883133757e-9,
        -5.188415197135356e-9, -8.101253245179797e-10, 6.318476828318098e-9,
        -7.805498095457974e-9, -8.69896704003609e-9, -4.112411937330503e-9,
        -1.673467124313779e-10, -7.363579041517219e-9] ± 6.557577e-08
        Minimum: 0.0000
        Maximum iterations: 20000
        Total independent runs: 10</code></pre><p>This output is telling us that the result from 10 independent runs is that vector defined as <em>design</em>, which is actually the mean value from the 10 runs, and it has a standard deviation. Note that this error is quite high because of the few runs executed, but as we increase the number of runs we might get better results.</p><h1><a class="nav-anchor" id="A-primer-on-numerical-optimization-1" href="#A-primer-on-numerical-optimization-1">A primer on numerical optimization</a></h1><p><strong>Optimization</strong> is a huge subject, and I don&#39;t think Newton even realized this when discovering Calculus, where optimization has its roots. Basically, in optimization we are trying to find <strong>the best</strong> possible solution to a given problem. Worded in this way it seems that optimization is actually everywhere we look around, which is so very true, optimization is everywhere!</p><p>Say you like to run, and you look at your milage, timings and so on; you start to wonder, what <em>is the best</em> way to <strong>improve</strong> my timings? How can I <strong>maximize</strong> it?</p><p>Now imagine that you have some money to spare and you wish to invest it. What type of investment will return the <strong>largest</strong> profit and will also <strong>minimize</strong> the possible risk of losing money?</p><p><em>Optimization</em> has been a major subject within <em>analysis</em>, the major branch of mathematics where most of its arguments come from. In mathematical language, we define an <strong>optimization problem</strong> as follows</p><div>\[\text{minimize} f(\mathbf{x}), \quad \mathbf{x} \in \mathbb{R} \\
\text{subject to } h(\mathbf{x}) = 0, \\
\text{and }g(\mathbf{x}) \leq 0 .
`
`
`\]</div><p><code>h</code> and <code>g</code> are referred to as <strong>constraint functions</strong>, and the full expressions with their equalities and inequalities are simply called <strong>constraints</strong>. When we have a problem like this, we call this a <strong>constrained optimization problem</strong>.</p><p>On the other hand, if we only define the problem as</p><div>\[\text{minimize} f(\mathbf{x}),\quad \mathbf{x} \in \mathbb{R}\]</div><p>we are talking about an <strong>unconstrained optimization problem</strong>.</p><p>The goal of optimization is to find the <em>vector</em> <code>\mathbf{x}</code> that gives the <strong>lowest</strong> possible value for <code>f</code> given all the constraints, if any. The classic way to achieve this is by using <em>derivatives</em> and <em>derivative tests</em>, and throughout the years mathematicians have developed very rigorous and robust algorithms to find these values. Almost every procedure uses <em>derivatives</em> because Newton and Gauss taught us that these <em>converge</em> faster and more precisely to the true values. But recently, <em>stochastic optimization</em> algorithms, were randomness is used to guide the search for the best value, have been very popular and widely used within the scientific community.</p><p>This is a very, very small space to talk about optimization, but the following references should get you started right away. <a href="#footnote-1">[1]</a>, <a href="#footnote-2">[2]</a> and <a href="#footnote-3">[3]</a>.</p><h1><a class="nav-anchor" id="On-Convergence-1" href="#On-Convergence-1">On Convergence</a></h1><p><strong>Convergence</strong> is a very strong word in mathematics, and it actually has lots of definitions depending on the specific branch of mathametics it is used. Here we shall use the <em>numerical analysis</em> definition, which is simply stated as a limit. We wish to obtain a value, whatever it is, in a finite time.</p><p>We may employ <em>tolerance</em> values where we argue that a given solution is <strong>close to</strong> the real value that I know of. We can see this in the example above, where we know that the true value is a <em>vector</em> filled with zeros, but we don&#39;t actually obtain zeros, instead we get <em>close</em> values to zeros within a certain <em>tolerance</em>: in this scenario we can say that the optimization algorithm <strong>has converged</strong>.</p><p>If, on the other hand, we rely on the number of <strong>maximum iterations</strong> then we can safely claim that when the algorithm has run for the number of <em>maximum iterations</em> then it has converged. Is that so? At least, in the realm of <a href="https://en.wikipedia.org/wiki/Approximation_algorithm">approximation algorithms</a> we can safely claim that this is true.</p><p>But don&#39;t take my word for it, in reality this is a very serious mathematical topic and should not be taken so slightly. Actually, every algorithm ever implemented must have a <strong>convergence analysis</strong> carried out for it, to ensure that either it will stop at some time or that it will given the desired result.</p><h1><a class="nav-anchor" id="The-basics-of-nature-and-bio-inspired-metaheuristics-1" href="#The-basics-of-nature-and-bio-inspired-metaheuristics-1">The basics of nature and bio-inspired metaheuristics</a></h1><p><strong>Nature and bio-inspired metaheuristics</strong> work by means of two fundamental <em>heuristics</em>: <strong>exploration</strong> and <strong>exploitation</strong>.</p><p>First, <strong>exploration</strong> is leveraged through the use of <em>random numbers</em>, these are created to try to cover most of the <em>search space</em>, i.e. the set of possible values that can be considered the solution to a given optimization problem. When <em>exploring</em> the <em>search space</em>, metaheuristics try to search as efficiently as possible, and most algorithms use <em>uniform sampling</em> to try and cover most, if not all, of the search space.</p><p>Once the <em>search space</em> has been explored, the algorithm tries to identify, by means of some update rule, which of these proposed solutions are actually valid. In <em>swarm intelligence</em> algorithms such as <a href="../algorithms/#implementations-docs-1"><code>Particle Swarm Optimization</code></a> the different particles are ranked and checked against each other to see which has the most promising value. Then, <strong>exploitation</strong> kicks in, trying to take advantage of this information and trying to pull most of the swarm towards it.</p><p>In the topic of optimization algorithms, <em>nature and bio-inspired metaheuristics</em> have a special place when talking about <em>convergence</em>, <em>stability</em>, and <em>significance.</em></p><p>First, <em>convergence</em> is usually measured as described in the section above, by means of a <em>tolerance</em> or a <em>maximum number</em> of iterations.</p><p><em>Stability</em> is a harder topic in this matter, because of the random aspect of most, if not all, of the current popular <em>nature and bio-inspired metaheuristics.</em> Reproduciblity is a big factor, and almost always algorithms need to be run independently <em>at least</em> 30 different times, with 30 statistically independent random number generators. But even this won&#39;t guarantee that every single run will give a good solution to the problem.</p><p>At last, <em>statistical significance</em> is almost mandatory if one wants to have a solution that has an actual mathematical and statistical <em>meaning.</em> Because of randomness, the actual mechanism by which <em>nature and bio-inspired metaheuristics</em> are Markov Chains <a href="#footnote-4">[4]</a> which provide statistical tools to guarantee and promise that the values found are, indeed, the real ones. <em>Hypothesis tests</em> like the parametric <em>t-test</em>, the <em>Mann-Whitney-Wilcoxon</em> non-parametric test, and some others are the most popular statistical tests to prove <em>significance</em> of the values obtained from applying <em>nature and bio-inspired metaheuristics.</em></p><h2><a class="nav-anchor" id="References-1" href="#References-1">References</a></h2><div class="footnote" id="footnote-4"><a href="#footnote-4"><strong>[4]</strong></a><p>Yang, X.-S. (2014). Nature-inspired optimization algorithms. In Elsevier Insights. <a href="https://doi.org/10.1007/978-981-10-6689-4_8">https://doi.org/10.1007/978-981-10-6689-4_8</a></p></div><div class="footnote" id="footnote-1"><a href="#footnote-1"><strong>[1]</strong></a><p>https://en.wikipedia.org/wiki/Mathematical_optimization#History</p></div><div class="footnote" id="footnote-2"><a href="#footnote-2"><strong>[2]</strong></a><p>https://web.stanford.edu/group/sisl/k12/optimization/MO-unit1-pdfs/1.1optimization.pdf</p></div><div class="footnote" id="footnote-3"><a href="#footnote-3"><strong>[3]</strong></a><p>https://sites.math.northwestern.edu/~clark/publications/opti.pdf</p></div><footer><hr/><a class="previous" href="../"><span class="direction">Previous</span><span class="title">Home</span></a><a class="next" href="../reference/"><span class="direction">Next</span><span class="title">Reference</span></a></footer></article></body></html>
