var documenterSearchIndex = {"docs":
[{"location":"benchmarks/#Benchmark-test-functions-1","page":"-","title":"Benchmark test functions","text":"","category":"section"},{"location":"benchmarks/#","page":"-","title":"-","text":"The following benchmark functions are implemented, every one is defined in the review[1]:","category":"page"},{"location":"benchmarks/#","page":"-","title":"-","text":"Sphere\nThe Sphere function is defined as:\nf(mathbfx) = sum_i=1^d x_i^2\nwith d the dimension of the design vector mathbfx, subject to 0 leq x_i leq 10.\nThe minimum is\nf(mathbfx^*) = 0 quad mathbfx^* = (0 cdots 0)\nEasom\nThe Easom function is defined as:\nf(mathbfx) = -cos(x_1) cos(x_2) exp-(x_1 - pi)^2 - (x_2 - pi)^2\nwhere the design vector is a 2-D vector only, subject to -100 leq x_i leq 100.\nThe function has the following minimum:\nf(mathbfx^*) = -1 quad mathbfx^* = (pi pi)","category":"page"},{"location":"benchmarks/#References-1","page":"-","title":"References","text":"","category":"section"},{"location":"benchmarks/#","page":"-","title":"-","text":"[1]: Jamil, M., & Yang, X. S. (2013). A literature survey of benchmark functions for global optimisation problems. International Journal of Mathematical Modelling and Numerical Optimisation, 4(2), 150–194. https://doi.org/10.1504/IJMMNO.2013.055204","category":"page"},{"location":"guide/#Who-is-this-package-for-1","page":"Guide","title":"Who is this package for","text":"","category":"section"},{"location":"guide/#","page":"Guide","title":"Guide","text":"This package should/could be used by:","category":"page"},{"location":"guide/#","page":"Guide","title":"Guide","text":"Practitioners: people in need of a black box optimization framework for when they know very little about the problem at hand.\nStudents: wanting to learn about nature-inspired algorithms, stochastic optimization or want a general survey of the current literature.\nResearchers: who want to employ different algorithms at once, test them or use them as comparison for their own developed algorithms.","category":"page"},{"location":"license/#","page":"License","title":"License","text":"Newtman.jl was created by Edwin Bedolla and the package can be used with the following license:","category":"page"},{"location":"license/#","page":"License","title":"License","text":"Copyright (c) 2019 Edwin BedollaPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","category":"page"},{"location":"reference/#Reference-1","page":"Reference","title":"Reference","text":"","category":"section"},{"location":"reference/#Benchmarks-1","page":"Reference","title":"Benchmarks","text":"","category":"section"},{"location":"reference/#","page":"Reference","title":"Reference","text":"Modules = [Newtman]\nPages = [\"functions.jl\",\n        \"implementations.jl\"]","category":"page"},{"location":"reference/#Newtman.Easom","page":"Reference","title":"Newtman.Easom","text":"Easom\n\nAn unconstrained implementation of the 2-dimensional Easom function defined as:\n\nf(mathbfx) = -cos(x_1) cos(x_2) exp-(x_1 - pi)^2 - (x_2 - pi)^2\n\nwhere x_1 and x_2 refer to the first and second element of the input vector mathbfx.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Newtman.Sphere","page":"Reference","title":"Newtman.Sphere","text":"Sphere\n\nAn unconstrained implementation of the Sphere function defined as:\n\nf(mathbfx) = sum_i=1^d x_i^2\n\nwhere d is the dimension of the input vector mathbfx.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Newtman.TestFunctions","page":"Reference","title":"Newtman.TestFunctions","text":"TestFunctions\n\nAbstract supertype for all benchmark functions.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Newtman.Unconstrained","page":"Reference","title":"Newtman.Unconstrained","text":"Unconstrained\n\nAbstract supertype for all unconstrained benchmark functions.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Algorithms-1","page":"Reference","title":"Algorithms","text":"","category":"section"},{"location":"reference/#","page":"Reference","title":"Reference","text":"Modules = [Newtman]\nPages = [\"solvers/pso.jl\", \"solvers/solvers.jl\"]","category":"page"},{"location":"reference/#Newtman.PSO","page":"Reference","title":"Newtman.PSO","text":"PSO\n\nPSO is the type associated with the implementation for the Particle Swarm Optimization with momentum. See Algorithms for more information.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Newtman.PSO-Tuple{Function,AbstractArray,Int64}","page":"Reference","title":"Newtman.PSO","text":"PSO(f::Function, population::AbstractArray, k_max::Int;\n    w=0.9, c1=2.0, c2=2.0)\n\nMethod that implements PSO for a function f of type Function.\n\nArguments\n\npopulation: can be any AbstractArray that contains Particle\n\ninstances, but it is expected to be generated by Population.\n\nk_max: number of maximum iterations until \"convergence\" of the algorithm.\n\nKeyword arguments\n\nIt is recommended to use the default values provided\n\nw: value that controls how much of the initial velocity is retained, i.e.\n\nan inertia term. This values decays linearly over each iteration until it reaches the default miminum value of 0.4.\n\nc1: balance between the influence of the individual's knowledge, i.e. the\n\nbest inidividual solution so far.\n\nc2: balance between the influence of the population's knowledge, i.e. the\n\nbest global solution so far.\n\nExamples\n\nusing Newtman\n\n# Define the Sphere function\nfunction f_sphere(x)\n    return sum(x .^ 2)\nend\n\n# Implement PSO for a 3-dimensional Sphere function, with\n# 10000 iterations and 30 particles in the population.\nval = PSO(f_sphere, Population(30, 3, -15.0, 15.0), 10000)\n\n\n\n\n\n","category":"method"},{"location":"reference/#Newtman.PSO-Tuple{Newtman.TestFunctions,AbstractArray,Int64}","page":"Reference","title":"Newtman.PSO","text":"PSO(f::TestFunctions, population::AbstractArray, k_max::Int;\n    w=0.9, c1=2.0, c2=2.0)\n\nMethod that implements PSO for a function f of type TestFunctions.\n\nArguments\n\npopulation: can be any AbstractArray that contains Particle\n\ninstances, but it is expected to be generated by Population.\n\nk_max: number of maximum iterations until \"convergence\" of the algorithm.\n\nKeyword arguments\n\nIt is recommended to use the default values provided\n\nw: value that controls how much of the initial velocity is retained, i.e.\n\nan inertia term. This values decays linearly over each iteration until it reaches the default miminum value of 0.4.\n\nc1: balance between the influence of the individual's knowledge, i.e. the\n\nbest inidividual solution so far.\n\nc2: balance between the influence of the population's knowledge, i.e. the\n\nbest global solution so far.\n\nExamples\n\nusing Newtman\n\n# Implement PSO for a 3-dimensional Sphere function, with\n# 10000 iterations and 25 particles in the population.\nval = PSO(Sphere(), Population(25, 3, -15.0, 15.0), 10000)\n\n\n\n\n\n","category":"method"},{"location":"reference/#Newtman.Metaheuristic","page":"Reference","title":"Newtman.Metaheuristic","text":"Metaheuristic\n\nAbstract type for metaheuristic algorithms, this makes a clear distinction between different classifications of metaheuristic algorithms.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Newtman.PopulationBase","page":"Reference","title":"Newtman.PopulationBase","text":"PopulationBase\n\nType for population-based algorithms that employ Population, i.e. subroutines that mutate an array of possible candidates in-place. An example of this type is PSO.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Newtman.Solver","page":"Reference","title":"Newtman.Solver","text":"Solver\n\nAbstract super-type for every algorithm implementation.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Population-1","page":"Reference","title":"Population","text":"","category":"section"},{"location":"reference/#","page":"Reference","title":"Reference","text":"Modules = [Newtman]\nPages = [\"population/types.jl\"]","category":"page"},{"location":"reference/#Newtman.Particle-Union{Tuple{V}, Tuple{T}, Tuple{T,T,T,V,V}} where V<:AbstractFloat where T<:AbstractArray","page":"Reference","title":"Newtman.Particle","text":"Particle(x::T, v::T, x_best::T, a::V, b::V)\n    where {T<:AbstractArray, V<:AbstractFloat}\n\nA type that can hold information about current position, current velocity, the best candidate to a solution, as well as defining the bounds. The dimensions of the Particle are inferred from the length of the arrays.\n\nArguments\n\nx: Array that holds the positions of possible solutions.\nv: Array that holds velocities related to x.\nx_best: An element of x that determines the best position for the particle.\na: lower bound for x\nb: upper bound for v\n\nExample\n\np = Particle(zeros(3), rand(3), zeros(3), -1.0, 1.0)\n\n\n\n\n\n","category":"method"},{"location":"reference/#Newtman.Particle-Union{Tuple{V}, Tuple{T}, Tuple{T,T,V}} where V<:Int64 where T<:AbstractFloat","page":"Reference","title":"Newtman.Particle","text":"Particle(a::T, b::T, n::V)\n    where {T<:AbstractFloat, V<:Int}\n\nParticle that can be created randomly using the bounds and the dimension needed.\n\nArguments\n\na: lower bound for x\nb: upper bound for v\nn: dimension for x, v, and x_best.\n\nExample\n\np = Particle(-1.0, 1.0, 3)\n\n\n\n\n\n","category":"method"},{"location":"reference/#Newtman.Population-Union{Tuple{V}, Tuple{T}, Tuple{T,T,V,V}} where V<:AbstractFloat where T<:Int64","page":"Reference","title":"Newtman.Population","text":"Population(num_particles::T, dim::T, a::V, b::V)\n    where {T<:Int, V<:AbstractFloat} -> Vector{Particle}(undef, num_particles)\n\nAn array of Particles where each of them are bounded and are given a dimension. This is essentially a multi-dimensional array. It makes handling Particles much easier.\n\nArguments\n\nnum_particles: Number of particles in the Population.\ndim: Dimension for every Particle.\na: Lower bound for every Particle, this is shared across every instance.\nb: Upper bound for every Particle, this is shared across every instance.\n\nExample\n\npop = Population(35, 4, -1.0, 1.0)\n\n\n\n\n\n","category":"method"},{"location":"reference/#Newtman.Population-Union{Tuple{V}, Tuple{T}, Tuple{T,V,V}} where V<:AbstractFloat where T<:Int64","page":"Reference","title":"Newtman.Population","text":"Population(dim::T, a::V, b::V)\n    where {T<:Int, V<:AbstractFloat} -> Vector{Particle}(undef, num_particles)\n\nIf num_particles is not provided, it defaults to 5 Particles in the Population.\n\nArguments\n\ndim: Dimension for every Particle.\na: Lower bound for every Particle, this is shared across every instance.\nb: Upper bound for every Particle, this is shared across every instance.\n\nExample\n\npop = Population(4, -1.0, 1.0) # The same as Population(5, 4, -1.0, 1.0)\n\n\n\n\n\n","category":"method"},{"location":"reference/#Newtman.Individual","page":"Reference","title":"Newtman.Individual","text":"Individual\n\nAbstract super-type for types that contain their own information.\n\n\n\n\n\n","category":"type"},{"location":"#Newtman.jl-1","page":"Home","title":"Newtman.jl","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"This is Newtman.jl, an stochastic optimization package that implements a number of metaheuristic algorithms, mostly nature-inspired and bio-inspired.","category":"page"},{"location":"#On-Metaheuristics-1","page":"Home","title":"On Metaheuristics","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"The term metaheuristic has a some history behind it, and a large span of definitions within the scientific community. In Newtman.jl, metaheuristic is defined as follows","category":"page"},{"location":"#","page":"Home","title":"Home","text":"A metaheuristic is a black box optimization framework that employs heuristics to find a close-to optimal solution for a given optimization problem.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"The definition is important in this context. Newtman.jl strives on implementations of already existent algorithms, but actually the term itself has not yet been acquired a formal definition, as Sörensen[1] says in his paper.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Because Newtman.jl employs metaheuristics as actual black box optimization frameworks, this definition should be enough to provide the actual purpose of the package.","category":"page"},{"location":"#Nature-and-bio-inspired-algorithms-1","page":"Home","title":"Nature and bio-inspired algorithms","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Heuristic is a term for a simple rule. Given a rule, mainly provided by experience, one can create a process or algorithm to solve a given problem.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Nature is an unlimited source of experience that can provide a lot of heuristics for us, if one looks closely.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Recent research has taken this approach[2] and scientists have taken inspiration from nature to create heuristics for problem solving. Examples are Ant Colony Optimization[3], based on the foraging behavior of ant colonies, Particle Swarm Optimization[4], which draws inspiration in the so-called swarm intelligence of birds, people, and so on.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"With this mindset, the field of stochastic optimization witnessed an avalanche of \"novel\" algorithms all based on nature, which were called nature-inspired metaheuristics.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"If one takes not only nature, but physics, chemistry and biology, one can create the so-called bio-inspired metaheuristics, based on ideas drawn from biological, chemical and physical processes.","category":"page"},{"location":"#The-need-for-Newtman.jl-and-nature-inspired-algorithms-1","page":"Home","title":"The need for Newtman.jl and nature-inspired algorithms","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Most metaheuristic algorithms are not very difficult to implement, and most of the time there is already a package for it (e.g. NiaPy for Python).","category":"page"},{"location":"#","page":"Home","title":"Home","text":"In general, these algorithms are not consistently used because there are more robust and exact algorithms out there, such as the classics BFGS, L-BFGS, Gradient Descent and many more.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"Nonetheless, there are several areas in optimization that need quick and approximate solutions, mostly because they are unsolvable in finite time[1]. Because of this, nature and bio-inspired algorithms rose to the top in some of these problems and were the only framework that could give a reasonable solution.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"When there is not much information about the problem (i.e. the derivative or gradient of the fitness function), or if the classic algorithms take too much time to converge, nature and bio-inspired algorithms tackle these types of problems with randomness and heuristics, and having found a close-to optimal solution, more robust algorithms can be applied to the given problem. [5]","category":"page"},{"location":"#About-using-Julia-1","page":"Home","title":"About using Julia","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"In scientific computing, the Julia programming language has been an excellent tool to get rid of the two language problem, i.e. when there is a need for high perfomance calculations but with low level manipulation, problems can be harder to code and even harder to solve. Julia is a great candidate to solve this problem, and this package attempts to prove that by providing high perfomant code and implementations.","category":"page"},{"location":"#Contents-of-Newtman.jl-1","page":"Home","title":"Contents of Newtman.jl","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Pages = [\"algorithms.md\", \"benchmarks.md\"]","category":"page"},{"location":"#The-Evolutionary-Computation-Bestiary-1","page":"Home","title":"The Evolutionary Computation Bestiary","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"There is a hidden goal for Newtman.jl and that is to implement all of the algorithms proposed in the EC Bestiary[6], which is a compilation of most of the nature and bio-inspired algorithms in the literature.","category":"page"},{"location":"#On-the-name-of-the-package-1","page":"Home","title":"On the name of the package","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Because of this hidden goal, the name Newtman was chosen, which is a pormanteau of the character by J.K. Rowling, Newton Scamander, whose purpose in life is to collect samples of fantastic beasts and create a book or log of their nature.","category":"page"},{"location":"#References-1","page":"Home","title":"References","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"[1]: Sörensen, K. (2015). Metaheuristics-the metaphor exposed. International Transactions in Operational Research, 22(1), 3–18. https://doi.org/10.1111/itor.12001","category":"page"},{"location":"#","page":"Home","title":"Home","text":"[2]: Kar, A. K. (2016). Bio inspired computing - A review of algorithms and scope of applications. Expert Systems with Applications, 59, 20–32. https://doi.org/10.1016/j.eswa.2016.04.018","category":"page"},{"location":"#","page":"Home","title":"Home","text":"[3]: Dorigo, M., & Di Caro, G. (1999, July). Ant colony optimization: a new meta-heuristic. In Proceedings of the 1999 congress on evolutionary computation-CEC99 (Cat. No. 99TH8406) (Vol. 2, pp. 1470-1477). IEEE.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"[4]: Eberhart, R., & Kennedy, J. (1995, November). Particle swarm optimization. In Proceedings of the IEEE international conference on neural networks (Vol. 4, pp. 1942-1948).","category":"page"},{"location":"#","page":"Home","title":"Home","text":"[5]: Luke, S. (2011). Essentials of metaheuristics. In Genetic Programming and Evolvable Machines (Vol. 12). https://doi.org/10.1007/s10710-011-9139-0","category":"page"},{"location":"#","page":"Home","title":"Home","text":"[6]: Felipe Campelo, & Claus Aranha. (2018, June 20). EC Bestiary: A bestiary of evolutionary, swarm and other metaphor-based algorithms (Version v2.0.1). Zenodo. http://doi.org/10.5281/zenodo.1293352","category":"page"},{"location":"algorithms/#Algorithms-1","page":"-","title":"Algorithms","text":"","category":"section"},{"location":"algorithms/#","page":"-","title":"-","text":"The following algorithms are implemented:","category":"page"},{"location":"algorithms/#","page":"-","title":"-","text":"Particle Swarm Optimization [1] This implementation is the modified Particle Swarm Optimization where it employs an inertia weight omega that controls convergence. This implementation uses linear decay for the inertia weight, which lowers the value of  omega until it reaches the default minimum of omega = 04. The update rules for the particles are the following:\nx_i+1 = x_i + v_i+1 \nv_i+1 = omega v_i + varphi_1 beta_1 (p_i - x_i) + varphi_2 beta_2 (p_g - x_i)\nwhere beta_1 and beta_2 are uniformly distributed random numbers; varphi_1 and varphi_2 are the momentum coefficients; p_i is the previous individual best position and p_g is the privious global best position of the population.","category":"page"},{"location":"algorithms/#References-1","page":"-","title":"References","text":"","category":"section"},{"location":"algorithms/#","page":"-","title":"-","text":"[1]: Eberhart, R. C., & Shi, Y. (2000, July). Comparing inertia weights and constriction factors in particle swarm optimization. In Proceedings of the 2000 congress on evolutionary computation. CEC00 (Cat. No. 00TH8512) (Vol. 1, pp. 84-88). IEEE.","category":"page"}]
}
