<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Implementations · Newtman.jl</title><link rel="canonical" href="https://edwinb-ai.github.io/Newtman.jl/dev/algorithms/"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">Newtman.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../guide/">Guide</a></li><li><a class="tocitem" href="../examples/">Examples</a></li><li class="is-active"><a class="tocitem" href>Implementations</a><ul class="internal"><li><a class="tocitem" href="#Particle-Swarm-Optimization"><span>Particle Swarm Optimization</span></a></li><li><a class="tocitem" href="#Simulated-Annealing"><span>Simulated Annealing</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><a class="tocitem" href="../benchmarks/">Benchmark functions</a></li><li><a class="tocitem" href="../reference/">Reference</a></li><li><a class="tocitem" href="../license/">License</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Implementations</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Implementations</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/edwinb-ai/Newtman.jl/blob/master/docs/src/algorithms.md#L" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="implementations-docs"><a class="docs-heading-anchor" href="#implementations-docs">Algorithms</a><a id="implementations-docs-1"></a><a class="docs-heading-anchor-permalink" href="#implementations-docs" title="Permalink"></a></h1><p>The following <strong>algorithms</strong> are implemented:</p><h2 id="Particle-Swarm-Optimization"><a class="docs-heading-anchor" href="#Particle-Swarm-Optimization">Particle Swarm Optimization</a><a id="Particle-Swarm-Optimization-1"></a><a class="docs-heading-anchor-permalink" href="#Particle-Swarm-Optimization" title="Permalink"></a></h2><p>This implementation is the modified Particle Swarm Optimization <sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup> where it employs an inertia weight <span>$\omega$</span> that controls convergence. This implementation uses <em>linear decay</em> for the inertia weight, which lowers the value of  <span>$\omega$</span> iteratively until it reaches the default minimum of <span>$\omega = 0.4$</span>.</p><p>The <strong>update rules</strong> for the particles are the following:</p><div>\[x_{i+1} = x_i + v_{i+1} \\
v_{i+1} = \omega v_i + \varphi_1 \beta_1 (p_i - x_i) + \varphi_2 \beta_2 (p_g - x_i) \\
\omega = \omega - \eta\]</div><p>where <span>$\beta_1$</span> and <span>$\beta_2$</span> are uniformly distributed random numbers; <span>$\varphi_1$</span> and <span>$\varphi_2$</span> are the momentum coefficients; <span>$p_i$</span> is the previous individual best position and <span>$p_g$</span> is the privious global best position of the population; finally <span>$\eta$</span> is the weight decay, currently implemented as</p><div>\[\eta = \frac{(0.9 - 0.4)}{n}\]</div><p>where <span>$0.9$</span> is the original default value for <span>$\omega$</span>, <span>$0.4$</span> is the default minimum as explained before and <span>$n$</span> is the total number of iterations the algorithm is run. This guarantees that the weight decays linearly.</p><h2 id="Simulated-Annealing"><a class="docs-heading-anchor" href="#Simulated-Annealing">Simulated Annealing</a><a id="Simulated-Annealing-1"></a><a class="docs-heading-anchor-permalink" href="#Simulated-Annealing" title="Permalink"></a></h2><h3 id="Classic-version"><a class="docs-heading-anchor" href="#Classic-version">Classic version</a><a id="Classic-version-1"></a><a class="docs-heading-anchor-permalink" href="#Classic-version" title="Permalink"></a></h3><p>This implementation <sup class="footnote-reference"><a id="citeref-2" href="#footnote-2">[2]</a></sup> uses the following logarithmic cooling schedule</p><div>\[T_{new}(t) = T_0 \frac{\log{(2)}}{\log{1 + t}}\]</div><p>to obtain a new temperature each iteration, starting from an initial temperature <span>$T_0$</span>.</p><p>This implementation searches possible candidate solutions by sampling from an approximate Boltzmann distribution, drawn as a normal distribution like so</p><div>\[g_{sol}(x) = \mathcal{N}(0, 1) * \sigma \\
x_{sol} = x_{prev} + g_{sol}(x)\]</div><p>where <span>$g_{sol}(x)$</span> is an array filled with random values sampled from an approximate normal standard distribution with standard deviation <span>$\sigma = \sqrt{T_{new}(t)}$</span> which corresponds to the previously found temperature. With this array, the new solution is computed as the previous (best) solution, <span>$x_{sol}$</span>, and adding the sampled array.</p><p>Finally, the Metropolis-Hastings algorithm is defined as</p><div>\[P(x_{sol} \leftarrow x_{old}) = 1.0 \qquad f(x_{sol}) &lt; f(x_{old}) \\
P(x_{sol} \leftarrow x_{old}) = e^{(\Delta / T_{new}(t))} \qquad f(x_{sol}) \geq f(x_{old})\]</div><p>where <span>$\Delta = f(x_{old}) - f(x_{sol})$</span>.</p><h3 id="Generalized-version"><a class="docs-heading-anchor" href="#Generalized-version">Generalized version</a><a id="Generalized-version-1"></a><a class="docs-heading-anchor-permalink" href="#Generalized-version" title="Permalink"></a></h3><p>This is the implementation developed by Tsallis &amp; Stariolo <sup class="footnote-reference"><a id="citeref-2" href="#footnote-2">[2]</a></sup> following Tsallis&#39; theory on the generalization of the extensive entropy developed in Statistical Mechanics. This implementation has as special cases the classic version described above and the <em>fast</em> version developed by Szu &amp; Hartley <sup class="footnote-reference"><a id="citeref-3" href="#footnote-3">[3]</a></sup>.</p><p>This implementation is quite interesting as it uses the Tsallis entropy defined <sup class="footnote-reference"><a id="citeref-4" href="#footnote-4">[4]</a></sup> as</p><div>\[S_q = k_B \frac{1-\sum_q p_i^q}{q_1}\]</div><p>where <span>$q$</span> is the so-called <strong>Tsallis parameter</strong>. By developing fundamental Statistical Mechanics theory and combining it with Gibbs&#39; ensemble theory (I&#39;m skipping all the development, it&#39;s quite extensive, pun intended), we arrive at a Metropolis-Hastings-like acceptance probability</p><div>\[P_{q_a}(x_{sol} \leftarrow x_{old}) = 1 \qquad f(x_{sol}) &lt; f(x_{old}) \\

P_{q_a}(x_{sol} \leftarrow x_{old}) = \frac{1}{[1+(q_a-1)\Delta / T_{new}(t)]^{(1/(q_a-1))}} \qquad f(x_{sol}) \geq f(x_{old})\]</div><p>there is a lot to unpack here, so we will go step by step.</p><p>Firstly, the <strong>cooling schedule</strong> is now defined as</p><div>\[T_{q_v}^V (t) = \frac{2^{q_v-1}-1}{(1+t)^{q_v-1}-1}\]</div><div>\[T_{new}(t) = T_0\ T_{q_v}^V (t)\]</div><p>where <span>$T_0$</span> is the initial temperature.</p><p>Then we have the neighbor sampling distribution defined as</p><div>\[g_{q_v}(\Delta x) = \left(\frac{q_{v}-1}{\pi}\right)^{D/2}

\frac{\Gamma\left(\frac{1}{q_{v}-1}+\frac{D-1}{2}\right)}{\Gamma\left(\frac{1}{q_{v}-1}-\frac{1}{2}\right)}

\frac{[T_{q_v}^V (t)]^{-\frac{D}{3-q_v}}}{\left(1+(q_v-1)\frac{(\Delta x)^2}{[T_{q_v}^V (t)]^{\frac{2}{3-q_v}}}\right)^{\frac{1}{q_V+1}+\frac{D-1}{2}}} \\

\forall D, \forall q_V\]</div><p>where <span>$\Delta x = x_{sol} - x_{old}$</span>, and <span>$\Gamma$</span> denotes the <a href="https://mathworld.wolfram.com/GammaFunction.html">Gamma function</a>. As you can see, this distribution is very complicated, but in the original paper <sup class="footnote-reference"><a id="citeref-2" href="#footnote-2">[2]</a></sup> Tsallis &amp; Stariolo provide an algorithm where they approximate this distribution as a <a href="https://en.wikipedia.org/wiki/L%C3%A9vy_distribution">Lévy distribution</a>. This algorithm is provided in the paper and it&#39;s the one used in this implementation.</p><p>With this, we update the neighbor solution as before <span>$x_{sol} = x_{old} + g_{q_v}(\Delta x)$</span> and then we employ the Metropolis-Hastings algorithm.</p><p>Lastly, an important case is when <span>$q_A &lt; 0$</span> because the update rule is now undetermined, so we employ the following update rule</p><div>\[P_{q_a}(x_{sol} \leftarrow x_{old}) = 1 \qquad f(x_{sol}) &lt; f(x_{old}) \\

P_{q_a}(x_{sol} \leftarrow x_{old}) = [1+(q_a-1)\Delta / T_{new}(t)]^{-1} \qquad f(x_{sol}) \geq f(x_{old})\]</div><p>which means that we always reject the solution <span>$x_{sol}$</span> whenever the proposition <span>$[1+(q_a-1)\Delta / T_{new}(t)] &lt; 0$</span> is true.</p><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a>Eberhart, R. C., &amp; Shi, Y. (2000, July). Comparing inertia weights and constriction factors in particle swarm optimization. In Proceedings of the 2000 congress on evolutionary computation. CEC00 (Cat. No. 00TH8512) (Vol. 1, pp. 84-88). IEEE.</li><li class="footnote" id="footnote-2"><a class="tag is-link" href="#citeref-2">2</a>C. Tsallis and D. A. Stariolo, “Generalized Simulated Annealing,” Physica A: Statistical Mechanics and its Applications, vol. 233, no. 1–2, pp. 395–406, Nov. 1996, doi: 10.1016/S0378-4371(96)00271-3.</li><li class="footnote" id="footnote-3"><a class="tag is-link" href="#citeref-3">3</a>Szu, H., &amp; Hartley, R. (1987). Fast simulated annealing. Physics letters A, 122(3-4), 157-162.</li><li class="footnote" id="footnote-4"><a class="tag is-link" href="#citeref-4">4</a>C. Tsallis, “Possible generalization of Boltzmann-Gibbs statistics,” J Stat Phys, vol. 52, no. 1, pp. 479–487, Jul. 1988, doi: 10.1007/BF01016429.</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../examples/">« Examples</a><a class="docs-footer-nextpage" href="../benchmarks/">Benchmark functions »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Wednesday 13 January 2021 21:15">Wednesday 13 January 2021</span>. Using Julia version 1.5.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
