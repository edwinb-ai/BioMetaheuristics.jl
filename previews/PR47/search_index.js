var documenterSearchIndex = {"docs":
[{"location":"benchmarks/#Benchmark-test-functions","page":"Benchmark functions","title":"Benchmark test functions","text":"","category":"section"},{"location":"benchmarks/","page":"Benchmark functions","title":"Benchmark functions","text":"The following benchmark functions are implemented in the submodule Newtman.TestFunctions. Each function is defined in the survey by Jamil and Yang[1]. We explain them in detail here for quick reference purposes. No other information more than the solutions to each of the optimization problems is provided.","category":"page"},{"location":"benchmarks/","page":"Benchmark functions","title":"Benchmark functions","text":"The purpose of these functions is to check the validity of the implementations in this package. By solving these benchmark optimization problems we can trust that the implemenations are correct and that they will give reasonable results in other similar problems. It is expected that virtually all implementations can solve these functions, or at least a considerable subset of these.","category":"page"},{"location":"benchmarks/","page":"Benchmark functions","title":"Benchmark functions","text":"The previous point is very important. Due to the No Free Lunch theorem[2] and its extension to metaheuristics[3], no single optimization algorithm is better than another for a set of optimization problems. This is a very important result, and one of the main reasons why most of the time some algorithms tend to perform better than other for a given optimization problem.","category":"page"},{"location":"benchmarks/#[Sphere](@ref)","page":"Benchmark functions","title":"Sphere","text":"","category":"section"},{"location":"benchmarks/","page":"Benchmark functions","title":"Benchmark functions","text":"The Sphere function is defined as:","category":"page"},{"location":"benchmarks/","page":"Benchmark functions","title":"Benchmark functions","text":"f(mathbfx) = sum_i=1^d x_i^2","category":"page"},{"location":"benchmarks/","page":"Benchmark functions","title":"Benchmark functions","text":"with d the dimension of the design vector mathbfx, normally evaluated within the bounds 0 leq x_i leq 10.","category":"page"},{"location":"benchmarks/","page":"Benchmark functions","title":"Benchmark functions","text":"solution: Solution\nf(mathbfx^*) = 0 quad mathbfx^* = (0 cdots 0)","category":"page"},{"location":"benchmarks/#[Easom](@ref)","page":"Benchmark functions","title":"Easom","text":"","category":"section"},{"location":"benchmarks/","page":"Benchmark functions","title":"Benchmark functions","text":"The Easom function is defined as:","category":"page"},{"location":"benchmarks/","page":"Benchmark functions","title":"Benchmark functions","text":"f(mathbfx) = -cos(x_1) cos(x_2) exp-(x_1 - pi)^2 - (x_2 - pi)^2","category":"page"},{"location":"benchmarks/","page":"Benchmark functions","title":"Benchmark functions","text":"where the design vector is a 2-D vector only. It is normally evaluated within the range -100 leq x_i leq 100.","category":"page"},{"location":"benchmarks/","page":"Benchmark functions","title":"Benchmark functions","text":"solution: Solution\nf(mathbfx^*) = -1 quad mathbfx^* = (pi pi)","category":"page"},{"location":"benchmarks/#[Ackley](@ref)","page":"Benchmark functions","title":"Ackley","text":"","category":"section"},{"location":"benchmarks/","page":"Benchmark functions","title":"Benchmark functions","text":"The Ackley function is defined as:","category":"page"},{"location":"benchmarks/","page":"Benchmark functions","title":"Benchmark functions","text":"f(mathbfx) = -20 expleft -002 sqrtfrac1dsum_i=1^dx_i^2 right\n- expleftfrac1dsum_i=1^dcos(2 pi x_i)right + 20 + e","category":"page"},{"location":"benchmarks/","page":"Benchmark functions","title":"Benchmark functions","text":"where the design vector is a d-dimensional vector. Normally evaluated within the range -35 leq x_i leq 35.","category":"page"},{"location":"benchmarks/","page":"Benchmark functions","title":"Benchmark functions","text":"solution: Solution\nf(mathbfx^*) = 0 quad mathbfx^* = (0 cdots 0)","category":"page"},{"location":"benchmarks/#[Rosenbrock](@ref)","page":"Benchmark functions","title":"Rosenbrock","text":"","category":"section"},{"location":"benchmarks/","page":"Benchmark functions","title":"Benchmark functions","text":"The famous Rosenbrock function is defined as:","category":"page"},{"location":"benchmarks/","page":"Benchmark functions","title":"Benchmark functions","text":"f(mathbfx) = sum_i=1^N-1 left100(x_i-1-x_i^2)^2 +(1-x_i)^2 right","category":"page"},{"location":"benchmarks/","page":"Benchmark functions","title":"Benchmark functions","text":"where the design vector is a N-dimensional vector. The search space range is normally -infty leq x_i leq infty.","category":"page"},{"location":"benchmarks/","page":"Benchmark functions","title":"Benchmark functions","text":"solution: Solution\nf(mathbfx^*) = 0 quad mathbfx^* = (1 cdots 1)","category":"page"},{"location":"benchmarks/#[GoldsteinPrice](@ref)","page":"Benchmark functions","title":"GoldsteinPrice","text":"","category":"section"},{"location":"benchmarks/","page":"Benchmark functions","title":"Benchmark functions","text":"The Goldstein-Price function is defined as:","category":"page"},{"location":"benchmarks/","page":"Benchmark functions","title":"Benchmark functions","text":"f(xy)=1 + (x + y + 1)^2(19  14x+3x^2 14y + 6xy + 3y^2) times \n30 + (2x  3y)^2(18  32x + 12x^2 + 4y  36xy + 27y^2)","category":"page"},{"location":"benchmarks/","page":"Benchmark functions","title":"Benchmark functions","text":"where x and y are the elements of a 2D design vector.","category":"page"},{"location":"benchmarks/","page":"Benchmark functions","title":"Benchmark functions","text":"solution: Solution\nf(mathbfx^*) = 3 quad mathbfx^* = (0 -1)","category":"page"},{"location":"benchmarks/#[Beale](@ref)","page":"Benchmark functions","title":"Beale","text":"","category":"section"},{"location":"benchmarks/","page":"Benchmark functions","title":"Benchmark functions","text":"The Beale function is defined as:","category":"page"},{"location":"benchmarks/","page":"Benchmark functions","title":"Benchmark functions","text":"f(x y) = (15-x+xy)^2+(225-x+xy^2)^2+(2625-x+xy^3)^2","category":"page"},{"location":"benchmarks/","page":"Benchmark functions","title":"Benchmark functions","text":"where x and y are the elements of a 2D design vector.","category":"page"},{"location":"benchmarks/","page":"Benchmark functions","title":"Benchmark functions","text":"solution: Solution\nf(mathbfx^*) = 0 quad mathbfx^* = (3 05)","category":"page"},{"location":"benchmarks/#[Levy](@ref)","page":"Benchmark functions","title":"Levy","text":"","category":"section"},{"location":"benchmarks/","page":"Benchmark functions","title":"Benchmark functions","text":"The Lévy function is defined as:","category":"page"},{"location":"benchmarks/","page":"Benchmark functions","title":"Benchmark functions","text":"f(mathbfx) = sin^2pi w_1 + sum_i=1^d-1 (w_i-1)^2 1+10sin^2pi w_1 + 1\n+ (w_d-1)^2 1+sin^22pi w_d","category":"page"},{"location":"benchmarks/","page":"Benchmark functions","title":"Benchmark functions","text":"where","category":"page"},{"location":"benchmarks/","page":"Benchmark functions","title":"Benchmark functions","text":"w_i = 1 + fracx_i-14","category":"page"},{"location":"benchmarks/","page":"Benchmark functions","title":"Benchmark functions","text":"and d is the dimension of the vector.","category":"page"},{"location":"benchmarks/","page":"Benchmark functions","title":"Benchmark functions","text":"solution: Solution\nf(mathbfx^*) = 0 quad mathbfx^* = (1 dots 1)","category":"page"},{"location":"benchmarks/#References","page":"Benchmark functions","title":"References","text":"","category":"section"},{"location":"benchmarks/","page":"Benchmark functions","title":"Benchmark functions","text":"[1]: Jamil, M., & Yang, X. S. (2013). A literature survey of benchmark functions for global optimisation problems. International Journal of Mathematical Modelling and Numerical Optimisation, 4(2), 150–194. https://doi.org/10.1504/IJMMNO.2013.055204","category":"page"},{"location":"benchmarks/","page":"Benchmark functions","title":"Benchmark functions","text":"[2]: Wolpert, D. H. and Macready, W. G. (1997) ‘No free lunch theorems for optimization’, IEEE Transactions on Evolutionary Computation, 1(1), pp. 67–82. doi: 10.1109/4235.585893.","category":"page"},{"location":"benchmarks/","page":"Benchmark functions","title":"Benchmark functions","text":"[3]: Joyce, T. and Herrmann, J. M. (2018) ‘A Review of No Free Lunch Theorems, and Their Implications for Metaheuristic Optimisation’, in Yang, X.-S. (ed.) Nature-Inspired Algorithms and Applied Optimization. Cham: Springer International Publishing (Studies in Computational Intelligence), pp. 27–51. doi: 10.1007/978-3-319-67669-2_2.","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"EditURL = \"<unknown>/docs/src/examples/api.jl\"","category":"page"},{"location":"api/#Parallel-evaluation-and-simple-statistics","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"","category":"section"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"In this example we will be looking at a way to evaluate several times a given problem by exploiting a distributed computing strategy known as embarrasingly parallel execution.","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"The idea is very simple: compute the same problem several times, in parallel, and collect the results at the end. This should work well with metaheuristics due to the following properties:","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"Metaheuristics are self-contained, meaning that they possess their own RNG and their own search space.\nDue to the fact that solutions are searched with a random component, independent runs should be able to give independent results.","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"With this in mind, we can use the fantastic parallel capabilities of Julia and show how easy it is to obtain some simple, but meaningful statistics for a given optimization problem.","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"With this we want to also show that this is the right way to use this package. We should always run several independent solvers to obtain good statistics. We must never settle with just one run from the solver.","category":"page"},{"location":"api/#Setting-up","page":"Parallel evaluation and simple statistics","title":"Setting up","text":"","category":"section"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"In order to use the multithreading capabilities of Julia, we need to launch the REPL using all the threads we can afford.","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"For instance, the computer where this example is currently being executed has 8 physical cores, so I should launch my Julia REPL like so","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"JULIA_NUM_THREADS=8 julia","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"This will launch the REPL with 8 cores ready to be used. We can check this by entering the following in the REPL,","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"julia> using Base.Threads\njulia> nthreads()","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"making sure that this matches the same number introduced with the variable JULIA_NUM_THREADS.","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"You should replace the number of threads, in this case 8, with the number of threads that you wish.","category":"page"},{"location":"api/#Code-set-up","page":"Parallel evaluation and simple statistics","title":"Code set up","text":"","category":"section"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"First, let us import all the necessary modules we will need for this example.","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"using Newtman\nusing Newtman.TestFunctions\nusing Base.Threads\nusing Statistics\nusing BenchmarkTools","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"Now, let us create some setup functions. First, we will be using the optimize interface to solve the Levy optimization problem. This function just wraps the optimize function and returns the solution vector from the problem.","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"We will be using Particle Swarm Optimization (PSO), with 20,000 iterations. It is very important to note that no specific RNG is being used. This tells the optimize function to always use a new, truly randomly seeded RNG.","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"function solve_problem(dim)\n    val = optimize(Levy(), zeros(dim), [-35.0, 35.0], PSO(); iters=20_000)\n\n    return val.x\nend;","category":"page"},{"location":"api/#Some-benchmarks","page":"Parallel evaluation and simple statistics","title":"Some benchmarks","text":"","category":"section"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"Before we continue, I would like to show a benchmark of the PSO implementation. We will use the fantastic BenchmarkTools.jl to check the time it takes to finish a single optimization problem.","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"Here, we will solve a 50-dimensional Levy optimization problem. We are not really interested if the solution is accurate, just the timing. We will deal with accuracy in the next subsection.","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"b = @benchmark solve_problem(50);\nb","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"BenchmarkTools.Trial: \n  memory estimate:  37.09 GiB\n  allocs estimate:  184553015\n  --------------\n  minimum time:     20.916 s (48.39% GC)\n  median time:      20.916 s (48.39% GC)\n  mean time:        20.916 s (48.39% GC)\n  maximum time:     20.916 s (48.39% GC)\n  --------------\n  samples:          1\n  evals/sample:     1","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"Not bad at all. If it takes between 3-4 seconds to finish I think this is fairly good. Furthermore, it means that we can take advantage of how little it takes to run in order to really push the number of solvers to execute.","category":"page"},{"location":"api/#Parallel-evaluation","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation","text":"","category":"section"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"We now turn to the main event. We will launch several solvers using the previously created wrapper function in parallel. First off, we need another function to do so.","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"This function will use the @threads macro that enables a for-loop to run in parallel. The function has a matrix called solutions where we will be storing the solution vectors from each independent run.","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"We will call the solver in parallel and each time we will save the solutions vector. We will then compute the mean, median and standard deviation from all the independent runs and report that as the true value, and compare it to the ground truth.","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"function parallel_compute(;dim=50, total_iterations=50)\n    solutions = Matrix{Float64}(undef, dim, total_iterations)\n\n    @threads for i in 1:total_iterations\n        solutions[:, i] = solve_problem(dim)\n    end\n\n    mean_result = mean(solutions; dims=2)\n    median_result = median(solutions; dims=2)\n    std_result = std(solutions; dims=2)\n\n    return (mean_result, median_result, std_result)\nend;","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"We are ready to go. We will do 200 iterations in order to have good statistics.","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"warning: Warning\nDepending on your hardware this might take a long time. If that is the case stop the process and reduce the number of iterations.","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"note: Note\nEvery time you do this exercise, new results will appear. This is normal for metaheuristics, and it is desired. We don't want reproducibility here, we aim for statistical significance.","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"μ, med, σ = parallel_compute(;total_iterations=200);","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"We can now check the results","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"Here is the mean value","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"μ'","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"1×50 LinearAlgebra.Adjoint{Float64,Array{Float64,2}}:\n 1.0  1.0  1.0  0.989071  1.0  1.0  1.0  1.0  1.0  0.994534  1.0  1.0  1.0  1.0  0.999999  1.0  1.0  1.0  0.994535  0.994535  1.0  0.994536  1.0  0.999999  1.0  1.0  0.989069  1.0  1.0  0.994535  0.999998  0.98907  0.98907  0.98907  0.994535  1.0  0.994535  1.0  0.994534  1.0  0.994535  1.0  0.999999  0.994535  0.994535  0.999999  1.0  0.994535  1.0  1.0","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"Here is the median obtained","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"med'","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"1×50 LinearAlgebra.Adjoint{Float64,Array{Float64,2}}:\n 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"And finally, the standard deviation of the solution","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"σ'","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"1×50 LinearAlgebra.Adjoint{Float64,Array{Float64,2}}:\n 5.85214e-6  8.49717e-6  5.11064e-6  0.109025  8.98645e-6  4.90472e-6  2.93619e-6  1.57354e-5  2.36602e-5  0.0772862  5.76815e-6  7.94483e-6  4.00857e-6  5.4588e-6  7.67163e-6  6.13454e-6  4.39584e-6  5.04256e-6  0.0772863  0.0772865  7.66157e-6  0.0772864  8.72139e-6  1.02898e-5  5.53272e-6  2.56498e-6  0.109024  1.02486e-5  6.3433e-6  0.0772864  1.40778e-5  0.109024  0.109025  0.109024  0.0772864  4.72514e-6  0.0772863  9.02386e-6  0.0772863  6.05015e-6  0.0772863  6.94921e-6  6.67594e-6  0.0772866  0.0772867  7.74873e-6  4.70179e-6  0.0772864  5.12988e-6  5.48866e-6","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"Let us print the evaluation of the function on these results. First, the mean value.","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"println(evaluate(Levy(), μ))","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"0.00047890369305421924\n","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"Then, the median obtained.","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"println(evaluate(Levy(), med))","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"2.250210231361768e-14\n","category":"page"},{"location":"api/#Conclusions","page":"Parallel evaluation and simple statistics","title":"Conclusions","text":"","category":"section"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"Recall that for the Levy function the solution is","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"mathbfx^* = (1 dots 1)","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"and it should evaluate to","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"f(mathbfx^*) = 0","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"It it safe to say that we have obtained those results, but we are statistically sure that these results are the true results, because we have several independent runs for the answer.","category":"page"},{"location":"api/#On-the-use-of-the-median","page":"Parallel evaluation and simple statistics","title":"On the use of the median","text":"","category":"section"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"Notice that most of the time, the median result actually performs better than the mean result. This is somewhat expected, as the median is not really affected by poorly performant runs. Sometimes, independent runs will not give good results and when taken into account, the mean value will suffer greatly from this. The median, however, as a measure of the \"value in the middle\", will not be so affected and a better estimation is expected.","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"We should always report both results, and conclude that whenever the final function evaluation is approximately the same with both the mean and the median, the solution is statistically acceptable for that particular problem.","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"","category":"page"},{"location":"api/","page":"Parallel evaluation and simple statistics","title":"Parallel evaluation and simple statistics","text":"This page was generated using Literate.jl.","category":"page"},{"location":"license/","page":"License","title":"License","text":"Newtman.jl was created by Edwin Bedolla and the package can be used with the following license:","category":"page"},{"location":"license/","page":"License","title":"License","text":"Copyright (c) 2019-2021 Edwin BedollaPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","category":"page"},{"location":"theory/#A-primer-on-numerical-optimization","page":"Theory","title":"A primer on numerical optimization","text":"","category":"section"},{"location":"theory/","page":"Theory","title":"Theory","text":"Optimization is a huge subject, and I don't think Newton even realized this when discovering Calculus, where optimization has its roots. Basically, in optimization we are trying to find the best possible solution to a given problem. Worded in this way it seems that optimization is actually everywhere we look around, which is so very true, optimization is everywhere!","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"Say you like to run, and you look at your milage, timings and so on; you start to wonder, what is the best way to improve my timings? How can I maximize it?","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"Now imagine that you have some money to spare and you wish to invest it. What type of investment will return the largest profit and will also minimize the possible risk of losing money?","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"Optimization has been a major subject within analysis, the major branch of mathematics where most of its arguments come from. In mathematical language, we define an optimization problem as follows","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"textminimize f(mathbfx) quad mathbfx in mathbbR \ntextsubject to  h(mathbfx) = 0 \ntextand g(mathbfx) leq 0 ","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"h and g are referred to as constraint functions, and the full expressions with their equalities and inequalities are simply called constraints. When we have a problem like this, we call this a constrained optimization problem.","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"On the other hand, if we only define the problem as","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"textminimize f(mathbfx)quad mathbfx in mathbbR","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"we are talking about an unconstrained optimization problem.","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"The goal of optimization is to find the vector mathbfx that gives the lowest possible value for f given all the constraints, if any. The classic way to achieve this is by using derivatives and derivative tests, and throughout the years mathematicians have developed very rigorous and robust algorithms to find these values. Almost every procedure uses derivatives because Newton and Gauss taught us that these converge faster and more precisely to the true values. But recently, stochastic optimization algorithms, were randomness is used to guide the search for the best value, have been very popular and widely used within the scientific community.","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"This is a very, very small space to talk about optimization, but the following references should get you started right away. [1], [2] and [3].","category":"page"},{"location":"theory/#On-Convergence","page":"Theory","title":"On Convergence","text":"","category":"section"},{"location":"theory/","page":"Theory","title":"Theory","text":"Convergence is a very strong word in mathematics, and it actually has lots of definitions depending on the specific branch of mathametics it is used. Here we shall use the numerical analysis definition, which is simply stated as a limit. We wish to obtain a value, whatever it is, in a finite time.","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"We may employ tolerance values where we argue that a given solution is close to the real value that I know of. We can see this in the example above, where we know that the true value is a vector filled with zeros, but we don't actually obtain zeros, instead we get close values to zeros within a certain tolerance: in this scenario we can say that the optimization algorithm has converged.","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"If, on the other hand, we rely on the number of maximum iterations then we can safely claim that when the algorithm has run for the number of maximum iterations then it has converged. Is that so? At least, in the realm of approximation algorithms we can safely claim that this is true.","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"But don't take my word for it, in reality this is a very serious mathematical topic and should not be taken so slightly. Actually, every algorithm ever implemented must have a convergence analysis carried out for it, to ensure that either it will stop at some time or that it will given the desired result.","category":"page"},{"location":"theory/#The-basics-of-nature-and-bio-inspired-metaheuristics","page":"Theory","title":"The basics of nature and bio-inspired metaheuristics","text":"","category":"section"},{"location":"theory/","page":"Theory","title":"Theory","text":"Nature and bio-inspired metaheuristics work by means of two fundamental heuristics: exploration and exploitation.","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"First, exploration is leveraged through the use of random numbers, these are created to try to cover most of the search space, i.e. the set of possible values that can be considered the solution to a given optimization problem. When exploring the search space, metaheuristics try to search as efficiently as possible, and most algorithms use uniform sampling to try and cover most, if not all, of the search space.","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"Once the search space has been explored, the algorithm tries to identify, by means of some update rule, which of these proposed solutions are actually valid. In swarm intelligence algorithms such as Particle Swarm Optimization the different particles are ranked and checked against each other to see which has the most promising value. Then, exploitation kicks in, trying to take advantage of this information and trying to pull most of the swarm towards it.","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"In the topic of optimization algorithms, nature and bio-inspired metaheuristics have a special place when talking about convergence, stability, and significance.","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"First, convergence is usually measured as described in the section above, by means of a tolerance or a maximum number of iterations.","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"Stability is a harder topic in this matter, because of the random aspect of most, if not all, of the current popular nature and bio-inspired metaheuristics. Reproduciblity is a big factor, and almost always algorithms need to be run independently at least 30 different times, with 30 statistically independent random number generators. But even this won't guarantee that every single run will give a good solution to the problem.","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"At last, statistical significance is almost mandatory if one wants to have a solution that has an actual mathematical and statistical meaning. Because of randomness, the actual mechanism by which nature and bio-inspired metaheuristics are Markov Chains [4] which provide statistical tools to guarantee and promise that the values found are, indeed, the real ones. Hypothesis tests like the parametric t-test, the Mann-Whitney-Wilcoxon non-parametric test, and some others are the most popular statistical tests to prove significance of the values obtained from applying nature and bio-inspired metaheuristics.","category":"page"},{"location":"theory/#References","page":"Theory","title":"References","text":"","category":"section"},{"location":"theory/","page":"Theory","title":"Theory","text":"[4]: Yang, X.-S. (2014). Nature-inspired optimization algorithms. In Elsevier Insights. https://doi.org/10.1007/978-981-10-6689-4_8","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"[1]: https://en.wikipedia.org/wiki/Mathematical_optimization#History","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"[2]: https://web.stanford.edu/group/sisl/k12/optimization/MO-unit1-pdfs/1.1optimization.pdf","category":"page"},{"location":"theory/","page":"Theory","title":"Theory","text":"[3]: https://sites.math.northwestern.edu/~clark/publications/opti.pdf","category":"page"},{"location":"examples/","page":"Implementations and proof of concept","title":"Implementations and proof of concept","text":"EditURL = \"<unknown>/docs/src/examples/examples.jl\"","category":"page"},{"location":"examples/#Implementations-and-proof-of-concept","page":"Implementations and proof of concept","title":"Implementations and proof of concept","text":"","category":"section"},{"location":"examples/","page":"Implementations and proof of concept","title":"Implementations and proof of concept","text":"In this examples I want to show some of the implementations and how they are used as a proof of concept. This means that we will use the \"low-level API\", i.e. calling the methods directly instead of the optimize interface.","category":"page"},{"location":"examples/","page":"Implementations and proof of concept","title":"Implementations and proof of concept","text":"Further, we wish to show that the implementations can at least solve some of the most common benchmark optimization problems.","category":"page"},{"location":"examples/","page":"Implementations and proof of concept","title":"Implementations and proof of concept","text":"Before we start, I will define a seed and an RNG to enable reproducibility of the results presented here.","category":"page"},{"location":"examples/","page":"Implementations and proof of concept","title":"Implementations and proof of concept","text":"using Random\n\nRANDOM_SEED = 458012;\nrng = MersenneTwister(RANDOM_SEED);","category":"page"},{"location":"examples/#Nonlinear-d-dimensional-global-optimization-problem","page":"Implementations and proof of concept","title":"Nonlinear d-dimensional global optimization problem","text":"","category":"section"},{"location":"examples/","page":"Implementations and proof of concept","title":"Implementations and proof of concept","text":"Using Newtman.jl is fairly straightforward, we will start by defining an d-dimensional nonlinear function to minimize, in this case we will use a popular function, the Griewank function defined as","category":"page"},{"location":"examples/","page":"Implementations and proof of concept","title":"Implementations and proof of concept","text":"f(mathbfx) = sum_i=1^d fracx_i^24000 - prod_i=1^d cosleft(\nfracx_isqrtiright) + 1","category":"page"},{"location":"examples/","page":"Implementations and proof of concept","title":"Implementations and proof of concept","text":"where d is the dimension of the problem. It's mostly evaluated within the boundaries -100 leq x_i leq 100, and it has a minimum at mathbf x^* = (0 cdots 0), and it evaluates to f(mathbfx^*) = 0.","category":"page"},{"location":"examples/","page":"Implementations and proof of concept","title":"Implementations and proof of concept","text":"We define the function in Julia like this","category":"page"},{"location":"examples/","page":"Implementations and proof of concept","title":"Implementations and proof of concept","text":"function griewank(x)\n    first_term = sum(x.^2) / 4000\n    # This variable will hold the result of the product,\n    # the second term in the function definition from above\n    second_term = 1.0\n    for (idx, val) in enumerate(x)\n        second_term *= cos(val / sqrt(idx))\n    end\n\n    return first_term - second_term + 1.0\nend;","category":"page"},{"location":"examples/","page":"Implementations and proof of concept","title":"Implementations and proof of concept","text":"Now, we wish to find the minimum of this function, and fortunately we know the true value so we can compare it later, we can use some of the implementations from Newtman.jl, for example, PSO. In this script we have chosen 30 particles within the population, d is equal to 20, next we define the boundaries and finally we declare that the algorithm will run for 20000 maximum iterations until it stops, having converged.","category":"page"},{"location":"examples/","page":"Implementations and proof of concept","title":"Implementations and proof of concept","text":"using Newtman\n\nval = PSO(\n    griewank,\n    Population(35, 10, -600.0, 600.0, rng),\n    20_000,\n    rng\n)\nprintln(val)","category":"page"},{"location":"examples/","page":"Implementations and proof of concept","title":"Implementations and proof of concept","text":"Results from Optimization\n\tAlgorithm: PSO\n\tSolution: [-1.2951243253091765e-6, 4.103266843628412e-6, -1.9912163226147196e-6, 4.4936413741072556e-6, 2.813628268436206e-6, 1.1256507815651895e-5, 9.97929061647118e-7, -3.0759921634749986e-6, 2.394042272909523e-6, -5.820201386836871e-6]\n\tMinimum: 0.0000\n\tMaximum iterations: 20000\n\n","category":"page"},{"location":"examples/","page":"Implementations and proof of concept","title":"Implementations and proof of concept","text":"Within a certain tolerance of about epsilon = 1 times 10^-6 we have found the global minimum of the function. We can actually check the value with the evaluation, notice that it actually returns 0, as expected.","category":"page"},{"location":"examples/","page":"Implementations and proof of concept","title":"Implementations and proof of concept","text":"griewank(val.x)","category":"page"},{"location":"examples/","page":"Implementations and proof of concept","title":"Implementations and proof of concept","text":"2.2315038705755796e-11","category":"page"},{"location":"examples/#Nonlinear-2-dimensional-global-optimization-problem","page":"Implementations and proof of concept","title":"Nonlinear 2-dimensional global optimization problem","text":"","category":"section"},{"location":"examples/","page":"Implementations and proof of concept","title":"Implementations and proof of concept","text":"Let us now tackle one of the most common optimization problems, which is finding the minimum of the Rosenbrock function which is a non-convex function, meaning that is does not have just one minimum or stationary point, it has several, so it is a difficult problem for classical optimization algorithms. In this example we will try to solve it using the SimulatedAnnealing implementation from Newtman.jl.","category":"page"},{"location":"examples/","page":"Implementations and proof of concept","title":"Implementations and proof of concept","text":"First, we define the Rosenbrock function in Julia","category":"page"},{"location":"examples/","page":"Implementations and proof of concept","title":"Implementations and proof of concept","text":"rosenbrock2d(x) =  (1.0 - x[1])^2 + 100.0 * (x[2] - x[1]^2)^2;","category":"page"},{"location":"examples/","page":"Implementations and proof of concept","title":"Implementations and proof of concept","text":"We will apply the Simulated Annealing algorithm to find the global optimum","category":"page"},{"location":"examples/","page":"Implementations and proof of concept","title":"Implementations and proof of concept","text":"val = SimulatedAnnealing(\n    rosenbrock2d, -5.0, 5.0, 2, rng; low_temp=10_000\n)\nprintln(val)","category":"page"},{"location":"examples/","page":"Implementations and proof of concept","title":"Implementations and proof of concept","text":"Results from Optimization\n\tAlgorithm: SimulatedAnnealing\n\tSolution: [1.028674409182762, 1.0597525306225808]\n\tMinimum: 0.0011\n\tMaximum iterations: 10000\n\n","category":"page"},{"location":"examples/","page":"Implementations and proof of concept","title":"Implementations and proof of concept","text":"Again, within a certain tolerance we find the expected result which is","category":"page"},{"location":"examples/","page":"Implementations and proof of concept","title":"Implementations and proof of concept","text":"mathbfx^* = (1 1)","category":"page"},{"location":"examples/","page":"Implementations and proof of concept","title":"Implementations and proof of concept","text":"and if we account for rounding errors and floating-point arithmetic, we can safely take this result as the best.","category":"page"},{"location":"examples/","page":"Implementations and proof of concept","title":"Implementations and proof of concept","text":"","category":"page"},{"location":"examples/","page":"Implementations and proof of concept","title":"Implementations and proof of concept","text":"This page was generated using Literate.jl.","category":"page"},{"location":"reference/#Reference","page":"Reference","title":"Reference","text":"","category":"section"},{"location":"reference/#API","page":"Reference","title":"API","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [Newtman]\nPages = [\"optimize.jl\"]\nPrivate = false","category":"page"},{"location":"reference/#Newtman.optimize-Tuple{Any,Any,Any,PopulationBase}","page":"Reference","title":"Newtman.optimize","text":"function optimize(f, sol, range, method::PopulationBase;\n    rng=nothing,\n    iters=2_000,\n    pop_size=30,\n    kwargs...\n) -> OptimizationResults\n\nThe optimize constitutes an interface to quickly dispatch over all the possible implementations.\n\nIn particular, this function dispatches over all PopulationBase implementations.\n\nArguments\n\nf: The function to optimize.\nsol: A candidate solution, should be an AbstractArray. The dimension of this array will determine the dimension of the problem.\nrange: A collection that contains just two elements, regarding the global bounds of the search space.\nmethod: A PopulationBase, e.g. PSO for Particle Swarm Optimization.\n\nKeyword arguments\n\nrng: An AbstractRNG object. This will be used for creating the population of solutions as well as for the implementation itself. If you wish to enforce reproducibility of results, create an RNG object with a set seed. If you do not pass an RNG object, a Xorshifts.Xoroshiro128Plus RNG will be created, using a truly random seed taken from the system.\niters: The total number of iterations for the main loop in the implementation.\npop_size: The total size of the population. The larger the population, the longer it will take to converge. A good population size is somewhere between 20-35.\nkwargs: Keyword arguments passed on to the particular implementation. Each implementation has its own keyword arguments so check the documentation for a specific implementation in order to modify these arguments.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Newtman.optimize-Tuple{Any,Any,Any,TrajectoryBase}","page":"Reference","title":"Newtman.optimize","text":"function optimize(f, sol, range, method::TrajectoryBase;\n    rng=nothing,\n    iters=2_000,\n    kwargs...\n) -> OptimizationResults\n\nThe optimize constitutes an interface to quickly dispatch over all the possible implementations.\n\nIn particular, this function dispatches over all TrajectoryBase implementations.\n\nArguments\n\nf: The function to optimize.\nsol: A candidate solution, should be an AbstractArray. The dimension of this array will determine the dimension of the problem.\nrange: A collection that contains just two elements, regarding the global bounds of the search space.\nmethod: A TrajectoryBase object, e.g. SimulatedAnnealing for the simulated annealing implementation.\n\nKeyword arguments\n\nrng: An AbstractRNG object. This will be used for creating the population of solutions as well as for the implementation itself. If you wish to enforce reproducibility of results, create an RNG object with a set seed. If you do not pass an RNG object, a Xorshifts.Xoroshiro128Plus RNG will be created, using a truly random seed taken from the system.\niters: The total number of iterations for the main loop in the implementation.\nkwargs: Keyword arguments passed on to the particular implementation. Each implementation has its own keyword arguments so check the documentation for a specific implementation in order to modify these arguments.\n\n\n\n\n\n","category":"method"},{"location":"reference/#Benchmarks","page":"Reference","title":"Benchmarks","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [Newtman.TestFunctions]\nPages = [\"TestFunctions.jl\", \"implementations.jl\"]","category":"page"},{"location":"reference/#Newtman.TestFunctions.Benchmark","page":"Reference","title":"Newtman.TestFunctions.Benchmark","text":"Benchmark\n\nAbstract supertype for all benchmark functions.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Newtman.TestFunctions.Unconstrained","page":"Reference","title":"Newtman.TestFunctions.Unconstrained","text":"Unconstrained\n\nAbstract supertype for all unconstrained benchmark functions.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Newtman.TestFunctions.Ackley","page":"Reference","title":"Newtman.TestFunctions.Ackley","text":"Ackley\n\nAn unconstrained implementation of the d-dimensional Ackley function defined as:\n\nf(mathbfx) = -20 e^ -002 sqrtfrac1dsum_i=1^dx_i^2 - e^frac1dsum_i=1^dcos(2 pi x_i) + 20 + e\n\nwhere d is the dimension of the input vector mathbfx.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Newtman.TestFunctions.Beale","page":"Reference","title":"Newtman.TestFunctions.Beale","text":"Beale\n\nAn unconstrained implementation of the d-dimensional Beale function defined as:\n\nf(x y) = (15-x+xy)^2+(225-x+xy^2)^2+(2625-x+xy^3)^2\n\n\n\n\n\n","category":"type"},{"location":"reference/#Newtman.TestFunctions.Easom","page":"Reference","title":"Newtman.TestFunctions.Easom","text":"Easom\n\nAn unconstrained implementation of the 2-dimensional Easom function defined as:\n\nf(mathbfx) = -cos(x_1) cos(x_2) exp-(x_1 - pi)^2 - (x_2 - pi)^2\n\nwhere x_1 and x_2 refer to the first and second element of the input vector mathbfx.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Newtman.TestFunctions.GoldsteinPrice","page":"Reference","title":"Newtman.TestFunctions.GoldsteinPrice","text":"Goldstein-Price\n\nAn unconstrained implementation of the d-dimensional Goldstein-Price function defined as:\n\nf(xy)=1 + (x + y + 1)^2(19  14x+3x^2 14y + 6xy + 3y^2) times \n30 + (2x  3y)^2(18  32x + 12x^2 + 4y  36xy + 27y^2)\n\n\n\n\n\n","category":"type"},{"location":"reference/#Newtman.TestFunctions.Levy","page":"Reference","title":"Newtman.TestFunctions.Levy","text":"Lévy\n\nAn unconstrained implementation of the d-dimensional Lévy function defined as:\n\nf(mathbfx) = sin^2pi w_1 + sum_i=1^d-1 (w_i-1)^2 1+10sin^2pi w_1 + 1\n+ (w_d-1)^2 1+sin^22pi w_d\n\nwhere\n\nw_i = 1 + fracx_i-14 and d is the dimension of the vector.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Newtman.TestFunctions.Rosenbrock","page":"Reference","title":"Newtman.TestFunctions.Rosenbrock","text":"Rosenbrock\n\nAn unconstrained implementation of the d-dimensional Rosenbrock function defined as:\n\nf(mathbfx) = sum_i=1^N-1 left100(x_i-1-x_i^2)^2 +(1-x_i)^2 right\n\nwhere N is the dimension of the input vector mathbfx.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Newtman.TestFunctions.Sphere","page":"Reference","title":"Newtman.TestFunctions.Sphere","text":"Sphere\n\nAn unconstrained implementation of the Sphere function defined as:\n\nf(mathbfx) = sum_i=1^d x_i^2\n\nwhere d is the dimension of the input vector mathbfx.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Algorithms","page":"Reference","title":"Algorithms","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [Newtman]\nPages = [\n    \"types/population.jl\",\n    \"types/solvers.jl\",\n    \"solvers/pso.jl\",\n    \"solvers/simulated_annealing.jl\"\n]\nPrivate = false","category":"page"},{"location":"reference/#Newtman.Particle-Tuple{Any,Any,Int64,Any}","page":"Reference","title":"Newtman.Particle","text":"Particle(a, b, n::Int)\n\nParticle that can be created randomly using the bounds and the dimension needed.\n\nArguments\n\na: lower bound for x and v.\nb: upper bound for x and v.\nn: dimension for x, v, and x_best.\n\nExample\n\np = Particle(-1.0, 1.0, 3)\n\n\n\n\n\n","category":"method"},{"location":"reference/#Newtman.Particle-Union{Tuple{T}, Tuple{AbstractArray{T,N} where N,AbstractArray{T,N} where N,AbstractArray{T,N} where N,T,T}} where T<:Real","page":"Reference","title":"Newtman.Particle","text":"Particle(\n    x::AbstractArray{T},\n    v::AbstractArray{T},\n    x_best::AbstractArray{T},\n    a::T,\n    b::T\n) where {T <: Real}\n\nA type that can hold information about current position, current velocity, the best candidate to a solution, as well as defining the bounds. The dimensions of the Particle are inferred from the length of the arrays.\n\nArguments\n\nx: Array that holds the positions of possible solutions.\nv: Array that holds velocities related to x.\nx_best: An element of x that determines the best position for the particle.\na: lower bound for x\nb: upper bound for v\n\nExample\n\np = Particle(zeros(3), rand(3), zeros(3), 0.0, 1.0)\n\n\n\n\n\n","category":"method"},{"location":"reference/#Newtman.Population-Tuple{Int64,Any,Any}","page":"Reference","title":"Newtman.Population","text":"Population(num_particles::Int, ranges; seed=nothing)\n    -> Vector{Particle}(undef, num_particles)\n\nAn array of Particle's where each of them are bounded and are given a dimension. x is a collection of ranges for each dimension for the Particle's specified.\n\nArguments\n\nnum_particles: Number of particles in the Population.\ndim: Dimension for every Particle.\nx: Should be a collection of ranges, for instance a tuple or a vector.\n\nExample\n\n# Two ranges, one for each dimension\nrange_a = SVector(-10.0, 10.0)\nrange_b = SVector(-2.5, 2.0)\npops = Population(2, 20, [ranges_a, range_b])\n\n\n\n\n\n","category":"method"},{"location":"reference/#Newtman.Population-Union{Tuple{T}, Tuple{T,T,Any,Any,Any}} where T<:Int64","page":"Reference","title":"Newtman.Population","text":"Population(num_particles::T, dim::T, a::V, b::V)\n    where {T<:Int, V<:AbstractFloat} -> Vector{Particle}(undef, num_particles)\n\nAn array of Particles where each of them are bounded and are given a dimension. This is essentially a multi-dimensional array. It makes handling Particles much easier.\n\nArguments\n\nnum_particles: Number of particles in the Population.\ndim: Dimension for every Particle.\na: Lower bound for every Particle, this is shared across every instance.\nb: Upper bound for every Particle, this is shared across every instance.\n\nExample\n\npop = Population(35, 4, -1.0, 1.0)\n\n\n\n\n\n","category":"method"},{"location":"reference/#Newtman.Metaheuristic","page":"Reference","title":"Newtman.Metaheuristic","text":"Metaheuristic\n\nAbstract type for metaheuristic algorithms, this makes a clear distinction between different classifications of metaheuristic algorithms.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Newtman.OptimizationResults","page":"Reference","title":"Newtman.OptimizationResults","text":"OptimizationResults{T, U}\n\nType that formats the output of Metaheuristic to get better information from it.\n\nFields\n\nx::T: Stores the solution array from the solver, i.e. the solution that minimizes   the cost function.\nmin::U: Stores the value obtained from evaluating the cost function with   x, i.e. the minima found.\nimpl::AbstractString: Stores the name of the Metaheuristic used, i.e. the name or identifier of the   optimization algorithm.\niterations::Integer: Stores the number of maximum iterations that the solver was run.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Newtman.PopulationBase","page":"Reference","title":"Newtman.PopulationBase","text":"PopulationBase <: Metaheuristic\n\nType for population-based algorithms that employ Population, i.e. subroutines that mutate an array of possible candidates in-place. An example of this type is PSO.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Newtman.TrajectoryBase","page":"Reference","title":"Newtman.TrajectoryBase","text":"TrajectoryBase <: Metaheuristic\n\nType for trajectory-based algorithms that only uses specific heuristics to guide the solution to a global minimum. An example of this type is SimulatedAnnealing.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Newtman.PSO","page":"Reference","title":"Newtman.PSO","text":"PSO <: PopulationBase\n\nPSO is the type associated with the implementation for the Particle Swarm Optimization with momentum. See Algorithms for more information.\n\n\n\n\n\n","category":"type"},{"location":"reference/#Newtman.PSO-Tuple{Function,Any,Int64,Any}","page":"Reference","title":"Newtman.PSO","text":"PSO(f::Function, population, k_max::Int, rng;\n    w=0.9, c1=2.0, c2=2.0\n) -> OptimizationResults\nPSO(f::Benchmark, population, k_max::Int, rng;\n    w=0.9, c1=2.0, c2=2.0\n) -> OptimizationResults\n\nMethod that implements PSO for a function f of type Function or of type Benchmark.\n\nReturns an OptimizationResults type with information relevant to the run executed, see OptimizationResults.\n\nArguments\n\npopulation: can be any AbstractArray that contains Particle\n\ninstances, but it is expected to be generated by Population.\n\nk_max: number of maximum iterations until \"convergence\" of the algorithm.\nrng: An object of type AbstractRNG.\n\nKeyword arguments\n\nIt is recommended to use the default values provided.\n\nw: value that controls how much of the initial velocity is retained, i.e. an inertia term. This values decays linearly over each iteration until it reaches\n\nthe default miminum value of 0.4.\n\nc1: balance between the influence of the individual's knowledge, i.e. the best inidividual solution so far.\nc2: balance between the influence of the population's knowledge, i.e. the best global solution so far.\nseed: an integer to be used as the seed for the pseudo random number generators. If nothing is passed (the default), then a random seed will be taken from the system.\n\nExamples\n\nusing Newtman\nusing Random\n\nrng = MersenneTwister(1261234)\n# Define the Sphere function\nf_sphere(x) = sum(x.^2)\n\n# Implement PSO for a 3-dimensional Sphere function, with\n# 10000 iterations and 30 particles in the population.\nval = PSO(f_sphere, Population(30, 3, -15.0, 15.0), 10_000, rng)\n\n\n\n\n\n","category":"method"},{"location":"reference/#Newtman.GeneralSimulatedAnnealing-Tuple{Function,Any,Any,Integer,Any}","page":"Reference","title":"Newtman.GeneralSimulatedAnnealing","text":"GeneralSimulatedAnnealing(f::Function, a, b, dim::Integer, rng;\n    low_temp=5_000, t0=500.0, qv=2.7, qa=-5.0\n) -> OptimizationResults\nGeneralSimulatedAnnealing(f::Benchmark, a, b, dim::Integer, rng;\n    low_temp=20_000, t0=500.0, qv=2.7, qa=-5.0\n) -> OptimizationResults\n\nImplementation of the generalized version of simulated annealing.\n\nThis implementation uses all the theory from Tsallis & Stariolo for the cooling schedule and the neighbor solution search. See GeneralSimulatedAnnealing for the implementation details.\n\nReturns an OptimizationResults type with information relevant to the run executed, see OptimizationResults.\n\nArguments\n\nf: any user defined Function that can take AbstractArray's.\na: lower bound for the solution search space.\nb: upper bound for the solution search space.\ndim: dimension of the optimization problem.\nrng: an object of type AbstractRNG.\n\nKeyword arguments\n\nIt is recommended to use the default values provided.\n\nt0: initial value for the temperature that is used. The default is an okay value, but should be changed depending on the optimization problem.\nlow_temp: total number of iterations, short for lowering temperature steps. This also corresponds to the famous Monte Carlo steps, which are the total number of steps until the algorithm finishes.\nqv: This is known as the Tsallis parameter; particularly this parameter controls the cooling schedule convergence and neighbor search. Positive values in the interval 153) are best because for values larger than 5/3 the neighbor search diverges.\nqa: Another Tsallis parameter; this particular parameter controls convergence for the Metropolis-Hastings algorithm and the acceptance probability involved. The more negative the value is, the better, but Tsallis & Stariolo report that the default value is best.\n\nExamples\n\nusing Newtman\nusing Random\n\nrng = MersenneTwister()\n# Define the 2D Rosenbrock function\nrosenbrock2d(x) =  (1.0 - x[1])^2 + 100.0 * (x[2] - x[1]^2)^2\n\n# Implement Simulated Annealing for a 2-dimensional Rosenbrock function, with\n# 15000 iterations and default values.\nval = GeneralSimulatedAnnealing(rosenbrock2d, -5.0, 5.0, 2, rng; low_temp=15_000)\n\n\n\n\n\n","category":"method"},{"location":"reference/#Newtman.SimulatedAnnealing-Tuple{Function,Any,Any,Integer,Any}","page":"Reference","title":"Newtman.SimulatedAnnealing","text":"SimulatedAnnealing(f::Function, a, b, dim::Integer, rng;\n    low_temp=5000, t0=500.0\n) -> OptimizationResults\nSimulatedAnnealing(f::Benchmark, a, b, dim::Integer, rng;\n    low_temp=5000, t0=500.0\n) -> OptimizationResults\n\nImplementation of the classical version of simulated annealing.\n\nThis implementation uses a logarithmic cooling schedule and searches possible candidate solutions by sampling from an approximated Boltzmann distribution, drawn as a normal distribution.\n\nReturns an OptimizationResults type with information relevant to the run executed, see OptimizationResults.\n\nArguments\n\nf: any user defined Function that can take AbstractArray's.\na: lower bound for the solution search space.\nb: upper bound for the solution search space.\ndim: dimension of the optimization problem.\nrng: an object of type AbstractRNG.\n\nKeyword arguments\n\nIt is recommended to use the default values provided.\n\nt0: initial value for the temperature that is used. The default is an okay value, but should be changed depending on the optimization problem.\nlow_temp: total number of iterations, short for lowering temperature steps. This also corresponds to the famous Monte Carlo steps, which are the total number of steps until the algorithm finishes.\n\nExamples\n\nusing Newtman\nusing Random\n\nrng = MersenneTwister()\n\n# Define the 2D Rosenbrock function\nrosenbrock2d(x) =  (1.0 - x[1])^2 + 100.0 * (x[2] - x[1]^2)^2\n\n# Implement Simulated Annealing for a 2-dimensional Rosenbrock function, with\n# 5000 iterations.\nval = SimulatedAnnealing(rosenbrock2d, -5.0, 5.0, 2, rng; low_temp=5000)\n\n\n\n\n\n","category":"method"},{"location":"#Newtman.jl","page":"Home","title":"Newtman.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This is Newtman.jl, an stochastic optimization package that implements a number of metaheuristic algorithms, mostly nature-inspired and bio-inspired.","category":"page"},{"location":"#Reach","page":"Home","title":"Reach","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This package should/could be used by:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Practitioners: people in need of a black box optimization framework for when they know very little about the problem at hand.\nStudents: wanting to learn about nature-inspired algorithms, stochastic optimization or want a general survey of the current literature.\nResearchers: who want to employ different algorithms at once, test them or use them as comparison for their own developed algorithms.","category":"page"},{"location":"#On-Metaheuristics","page":"Home","title":"On Metaheuristics","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The term metaheuristic has some history behind it, and a large span of definitions within the scientific community. In Newtman.jl, metaheuristic is defined as follows","category":"page"},{"location":"","page":"Home","title":"Home","text":"A metaheuristic is a black box optimization framework that employs heuristics to find a close-to optimal solution for a given optimization problem.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The definition is important in this context. Newtman.jl strives on implementations of already existent algorithms, but actually the term itself has not yet been acquired a formal definition, as Sörensen[1] says in his paper.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Because Newtman.jl employs metaheuristics as actual black box optimization frameworks, this definition should be enough to provide the actual purpose of the package.","category":"page"},{"location":"#Nature-and-bio-inspired-algorithms","page":"Home","title":"Nature and bio-inspired algorithms","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Heuristic is a term for a simple rule. Given a rule, mainly provided by experience, one can create a process or algorithm to solve a given problem.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Nature is an unlimited source of experience that can provide a lot of heuristics for us, if one looks closely.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Recent research has taken this approach[2] and scientists have taken inspiration from nature to create heuristics for problem solving. Examples are Ant Colony Optimization[3], based on the foraging behavior of ant colonies, Particle Swarm Optimization[4], which draws inspiration in the so-called swarm intelligence of birds, people, and so on.","category":"page"},{"location":"","page":"Home","title":"Home","text":"With this mindset, the field of stochastic optimization witnessed an avalanche of \"novel\" algorithms all based on nature, which were called nature-inspired metaheuristics.","category":"page"},{"location":"","page":"Home","title":"Home","text":"If one takes not only nature, but physics, chemistry and biology, one can create the so-called bio-inspired metaheuristics, based on ideas drawn from biological, chemical and physical processes.","category":"page"},{"location":"#The-need-for-Newtman.jl-and-nature-inspired-algorithms","page":"Home","title":"The need for Newtman.jl and nature-inspired algorithms","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Most metaheuristic algorithms are not very difficult to implement, and most of the time there is already a package for it (e.g. NiaPy for Python).","category":"page"},{"location":"","page":"Home","title":"Home","text":"In general, these algorithms are not consistently used because there are more robust and exact algorithms out there, such as the classics BFGS, L-BFGS, Gradient Descent and many more.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Nonetheless, there are several areas in optimization that need quick and approximate solutions, mostly because they are unsolvable in finite time[1]. Because of this, nature and bio-inspired algorithms rose to the top in some of these problems and were the only framework that could give a reasonable solution.","category":"page"},{"location":"","page":"Home","title":"Home","text":"When there is not much information about the problem (i.e. the derivative or gradient of the fitness function), or if the classic algorithms take too much time to converge, nature and bio-inspired algorithms tackle these types of problems with randomness and heuristics, and having found a close-to optimal solution, more robust algorithms can be applied to the given problem. [5]","category":"page"},{"location":"#About-using-Julia","page":"Home","title":"About using Julia","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"In scientific computing, the Julia programming language has been an excellent tool to get rid of the two language problem, i.e. when there is a need for high perfomance calculations but with low level manipulation, problems can be harder to code and even harder to solve. Julia is a great candidate to solve this problem, and this package attempts to prove that by providing high perfomant code and implementations.","category":"page"},{"location":"#The-Evolutionary-Computation-Bestiary","page":"Home","title":"The Evolutionary Computation Bestiary","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"There is a hidden goal for Newtman.jl and that is to implement all of the algorithms proposed in the EC Bestiary[6], which is a compilation of most of the nature and bio-inspired algorithms in the literature.","category":"page"},{"location":"#On-the-name-of-the-package","page":"Home","title":"On the name of the package","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Because of this hidden goal, the name Newtman was chosen, which is a pormanteau of the character by J.K. Rowling, Newton Scamander, whose purpose in life is to collect samples of fantastic beasts and create a book or log of their nature.","category":"page"},{"location":"#References","page":"Home","title":"References","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"[1]: Sörensen, K. (2015). Metaheuristics-the metaphor exposed. International Transactions in Operational Research, 22(1), 3–18.","category":"page"},{"location":"","page":"Home","title":"Home","text":"[2]: Kar, A. K. (2016). Bio inspired computing - A review of algorithms and scope of applications. Expert Systems with Applications, 59, 20–32.","category":"page"},{"location":"","page":"Home","title":"Home","text":"[3]: Dorigo, M., & Di Caro, G. (1999, July). Ant colony optimization: a new meta-heuristic. In Proceedings of the 1999 congress on evolutionary computation-CEC99 (Cat. No. 99TH8406) (Vol. 2, pp. 1470-1477). IEEE.","category":"page"},{"location":"","page":"Home","title":"Home","text":"[4]: Eberhart, R., & Kennedy, J. (1995, November). Particle swarm optimization. In Proceedings of the IEEE international conference on neural networks (Vol. 4, pp. 1942-1948).","category":"page"},{"location":"","page":"Home","title":"Home","text":"[5]: Luke, S. (2011). Essentials of metaheuristics. In Genetic Programming and Evolvable Machines (Vol. 12).","category":"page"},{"location":"","page":"Home","title":"Home","text":"[6]: Felipe Campelo, & Claus Aranha. (2018, June 20). EC Bestiary: A bestiary of evolutionary, swarm and other metaphor-based algorithms (Version v2.0.1). Zenodo.","category":"page"},{"location":"algorithms/#implementations-docs","page":"Implementations","title":"Algorithms","text":"","category":"section"},{"location":"algorithms/","page":"Implementations","title":"Implementations","text":"The following algorithms are implemented:","category":"page"},{"location":"algorithms/#Particle-Swarm-Optimization","page":"Implementations","title":"Particle Swarm Optimization","text":"","category":"section"},{"location":"algorithms/","page":"Implementations","title":"Implementations","text":"This implementation is the modified Particle Swarm Optimization [1] where it employs an inertia weight omega that controls convergence. This implementation uses linear decay for the inertia weight, which lowers the value of  omega iteratively until it reaches the default minimum of omega = 04.","category":"page"},{"location":"algorithms/","page":"Implementations","title":"Implementations","text":"The update rules for the particles are the following:","category":"page"},{"location":"algorithms/","page":"Implementations","title":"Implementations","text":"x_i+1 = x_i + v_i+1 \nv_i+1 = omega v_i + varphi_1 beta_1 (p_i - x_i) + varphi_2 beta_2 (p_g - x_i) \nomega = omega - eta","category":"page"},{"location":"algorithms/","page":"Implementations","title":"Implementations","text":"where beta_1 and beta_2 are uniformly distributed random numbers; varphi_1 and varphi_2 are the momentum coefficients; p_i is the previous individual best position and p_g is the privious global best position of the population; finally eta is the weight decay, currently implemented as","category":"page"},{"location":"algorithms/","page":"Implementations","title":"Implementations","text":"eta = frac(09 - 04)n","category":"page"},{"location":"algorithms/","page":"Implementations","title":"Implementations","text":"where 09 is the original default value for omega, 04 is the default minimum as explained before and n is the total number of iterations the algorithm is run. This guarantees that the weight decays linearly.","category":"page"},{"location":"algorithms/#Simulated-Annealing","page":"Implementations","title":"Simulated Annealing","text":"","category":"section"},{"location":"algorithms/#Classic-version","page":"Implementations","title":"Classic version","text":"","category":"section"},{"location":"algorithms/","page":"Implementations","title":"Implementations","text":"This implementation [2] uses the following logarithmic cooling schedule","category":"page"},{"location":"algorithms/","page":"Implementations","title":"Implementations","text":"T_new(t) = T_0 fraclog(2)log1 + t","category":"page"},{"location":"algorithms/","page":"Implementations","title":"Implementations","text":"to obtain a new temperature each iteration, starting from an initial temperature T_0.","category":"page"},{"location":"algorithms/","page":"Implementations","title":"Implementations","text":"This implementation searches possible candidate solutions by sampling from an approximate Boltzmann distribution, drawn as a normal distribution like so","category":"page"},{"location":"algorithms/","page":"Implementations","title":"Implementations","text":"g_sol(x) = mathcalN(0 1) * sigma \nx_sol = x_prev + g_sol(x)","category":"page"},{"location":"algorithms/","page":"Implementations","title":"Implementations","text":"where g_sol(x) is an array filled with random values sampled from an approximate normal standard distribution with standard deviation sigma = sqrtT_new(t) which corresponds to the previously found temperature. With this array, the new solution is computed as the previous (best) solution, x_sol, and adding the sampled array.","category":"page"},{"location":"algorithms/","page":"Implementations","title":"Implementations","text":"Finally, the Metropolis-Hastings algorithm is defined as","category":"page"},{"location":"algorithms/","page":"Implementations","title":"Implementations","text":"P(x_sol leftarrow x_old) = 10 qquad f(x_sol)  f(x_old) \nP(x_sol leftarrow x_old) = e^(Delta  T_new(t)) qquad f(x_sol) geq f(x_old)","category":"page"},{"location":"algorithms/","page":"Implementations","title":"Implementations","text":"where Delta = f(x_old) - f(x_sol).","category":"page"},{"location":"algorithms/#generalized-sm","page":"Implementations","title":"Generalized version","text":"","category":"section"},{"location":"algorithms/","page":"Implementations","title":"Implementations","text":"This is the implementation developed by Tsallis & Stariolo [2] following Tsallis' theory on the generalization of the extensive entropy developed in Statistical Mechanics. This implementation has as special cases the classic version described above and the fast version developed by Szu & Hartley [3].","category":"page"},{"location":"algorithms/","page":"Implementations","title":"Implementations","text":"This implementation is quite interesting as it uses the Tsallis entropy defined [4] as","category":"page"},{"location":"algorithms/","page":"Implementations","title":"Implementations","text":"S_q = k_B frac1-sum_q p_i^qq_1","category":"page"},{"location":"algorithms/","page":"Implementations","title":"Implementations","text":"where q is the so-called Tsallis parameter. By developing fundamental Statistical Mechanics theory and combining it with Gibbs' ensemble theory (I'm skipping all the development, it's quite extensive, pun intended), we arrive at a Metropolis-Hastings-like acceptance probability","category":"page"},{"location":"algorithms/","page":"Implementations","title":"Implementations","text":"P_q_a(x_sol leftarrow x_old) = 1 qquad f(x_sol)  f(x_old) \n\nP_q_a(x_sol leftarrow x_old) = frac11+(q_a-1)Delta  T_new(t)^(1(q_a-1)) qquad f(x_sol) geq f(x_old)","category":"page"},{"location":"algorithms/","page":"Implementations","title":"Implementations","text":"there is a lot to unpack here, so we will go step by step.","category":"page"},{"location":"algorithms/","page":"Implementations","title":"Implementations","text":"Firstly, the cooling schedule is now defined as","category":"page"},{"location":"algorithms/","page":"Implementations","title":"Implementations","text":"T_q_v^V (t) = frac2^q_v-1-1(1+t)^q_v-1-1","category":"page"},{"location":"algorithms/","page":"Implementations","title":"Implementations","text":"T_new(t) = T_0 T_q_v^V (t)","category":"page"},{"location":"algorithms/","page":"Implementations","title":"Implementations","text":"where T_0 is the initial temperature.","category":"page"},{"location":"algorithms/","page":"Implementations","title":"Implementations","text":"Then we have the neighbor sampling distribution defined as","category":"page"},{"location":"algorithms/","page":"Implementations","title":"Implementations","text":"g_q_v(Delta x) = left(fracq_v-1piright)^D2\n\nfracGammaleft(frac1q_v-1+fracD-12right)Gammaleft(frac1q_v-1-frac12right)\n\nfracT_q_v^V (t)^-fracD3-q_vleft(1+(q_v-1)frac(Delta x)^2T_q_v^V (t)^frac23-q_vright)^frac1q_V+1+fracD-12 \n\nforall D forall q_V","category":"page"},{"location":"algorithms/","page":"Implementations","title":"Implementations","text":"where Delta x = x_sol - x_old, and Gamma denotes the Gamma function. As you can see, this distribution is very complicated, but in the original paper [2] Tsallis & Stariolo provide an algorithm where they approximate this distribution as a Lévy distribution. This algorithm is provided in the paper and it's the one used in this implementation.","category":"page"},{"location":"algorithms/","page":"Implementations","title":"Implementations","text":"With this, we update the neighbor solution as before x_sol = x_old + g_q_v(Delta x) and then we employ the Metropolis-Hastings algorithm.","category":"page"},{"location":"algorithms/","page":"Implementations","title":"Implementations","text":"Lastly, an important case is when q_A  0 because the update rule is now undetermined, so we employ the following update rule","category":"page"},{"location":"algorithms/","page":"Implementations","title":"Implementations","text":"P_q_a(x_sol leftarrow x_old) = 1 qquad f(x_sol)  f(x_old) \n\nP_q_a(x_sol leftarrow x_old) = 1+(q_a-1)Delta  T_new(t)^-1 qquad f(x_sol) geq f(x_old)","category":"page"},{"location":"algorithms/","page":"Implementations","title":"Implementations","text":"which means that we always reject the solution x_sol whenever the proposition 1+(q_a-1)Delta  T_new(t)  0 is true.","category":"page"},{"location":"algorithms/#References","page":"Implementations","title":"References","text":"","category":"section"},{"location":"algorithms/","page":"Implementations","title":"Implementations","text":"[1]: Eberhart, R. C., & Shi, Y. (2000, July). Comparing inertia weights and constriction factors in particle swarm optimization. In Proceedings of the 2000 congress on evolutionary computation. CEC00 (Cat. No. 00TH8512) (Vol. 1, pp. 84-88). IEEE.","category":"page"},{"location":"algorithms/","page":"Implementations","title":"Implementations","text":"[2]: C. Tsallis and D. A. Stariolo, “Generalized Simulated Annealing,” Physica A: Statistical Mechanics and its Applications, vol. 233, no. 1–2, pp. 395–406, Nov. 1996, doi: 10.1016/S0378-4371(96)00271-3.","category":"page"},{"location":"algorithms/","page":"Implementations","title":"Implementations","text":"[3]: Szu, H., & Hartley, R. (1987). Fast simulated annealing. Physics letters A, 122(3-4), 157-162.","category":"page"},{"location":"algorithms/","page":"Implementations","title":"Implementations","text":"[4]: C. Tsallis, “Possible generalization of Boltzmann-Gibbs statistics,” J Stat Phys, vol. 52, no. 1, pp. 479–487, Jul. 1988, doi: 10.1007/BF01016429.","category":"page"}]
}
